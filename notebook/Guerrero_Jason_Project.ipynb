{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Jason Guerrero <br/>\n",
    "USCID: 5466170786 <br/>\n",
    "GitHub: JasonTGuerrero <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense, Dropout, Conv1D, MaxPooling1D, LSTM\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/jasonguerrero/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.1\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSPATH = \"../data/pos/\"\n",
    "NEGPATH = \"../data/neg/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Data Exploration and Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cv839_21467.txt': 1, 'cv034_29647.txt': 1, 'cv908_16009.txt': 1, 'cv748_12786.txt': 1, 'cv253_10077.txt': 1, 'cv147_21193.txt': 1, 'cv962_9803.txt': 1, 'cv686_13900.txt': 1, 'cv410_24266.txt': 1, 'cv913_29252.txt': 1, 'cv695_21108.txt': 1, 'cv601_23453.txt': 1, 'cv490_17872.txt': 1, 'cv518_13331.txt': 1, 'cv157_29372.txt': 1, 'cv570_29082.txt': 1, 'cv289_6463.txt': 1, 'cv098_15435.txt': 1, 'cv656_24201.txt': 1, 'cv878_15694.txt': 1, 'cv172_11131.txt': 1, 'cv152_8736.txt': 1, 'cv762_13927.txt': 1, 'cv028_26746.txt': 1, 'cv756_22540.txt': 1, 'cv595_25335.txt': 1, 'cv701_14252.txt': 1, 'cv407_22637.txt': 1, 'cv794_15868.txt': 1, 'cv000_29590.txt': 1, 'cv375_9929.txt': 1, 'cv891_6385.txt': 1, 'cv198_18180.txt': 1, 'cv161_11425.txt': 1, 'cv440_15243.txt': 1, 'cv497_26980.txt': 1, 'cv090_0042.txt': 1, 'cv382_7897.txt': 1, 'cv383_13116.txt': 1, 'cv625_12440.txt': 1, 'cv234_20643.txt': 1, 'cv217_28842.txt': 1, 'cv545_12014.txt': 1, 'cv367_22792.txt': 1, 'cv209_29118.txt': 1, 'cv449_8785.txt': 1, 'cv579_11605.txt': 1, 'cv832_23275.txt': 1, 'cv785_22600.txt': 1, 'cv719_5713.txt': 1, 'cv510_23360.txt': 1, 'cv219_18626.txt': 1, 'cv645_15668.txt': 1, 'cv994_12270.txt': 1, 'cv306_10364.txt': 1, 'cv278_13041.txt': 1, 'cv956_11609.txt': 1, 'cv644_17154.txt': 1, 'cv624_10744.txt': 1, 'cv563_17257.txt': 1, 'cv026_29325.txt': 1, 'cv904_24353.txt': 1, 'cv511_10132.txt': 1, 'cv544_5108.txt': 1, 'cv810_12458.txt': 1, 'cv955_25001.txt': 1, 'cv680_10160.txt': 1, 'cv154_9328.txt': 1, 'cv685_5947.txt': 1, 'cv055_8338.txt': 1, 'cv489_17906.txt': 1, 'cv331_8273.txt': 1, 'cv777_10094.txt': 1, 'cv188_19226.txt': 1, 'cv166_11052.txt': 1, 'cv216_18738.txt': 1, 'cv293_29856.txt': 1, 'cv549_21443.txt': 1, 'cv494_17389.txt': 1, 'cv451_10690.txt': 1, 'cv477_22479.txt': 1, 'cv363_29332.txt': 1, 'cv581_19381.txt': 1, 'cv250_25616.txt': 1, 'cv813_6534.txt': 1, 'cv290_11084.txt': 1, 'cv381_20172.txt': 1, 'cv139_12873.txt': 1, 'cv937_9811.txt': 1, 'cv781_5262.txt': 1, 'cv348_18176.txt': 1, 'cv915_8841.txt': 1, 'cv044_16969.txt': 1, 'cv969_13250.txt': 1, 'cv237_19221.txt': 1, 'cv432_14224.txt': 1, 'cv657_24513.txt': 1, 'cv998_14111.txt': 1, 'cv469_20630.txt': 1, 'cv078_14730.txt': 1, 'cv160_10362.txt': 1, 'cv215_22240.txt': 1, 'cv391_10802.txt': 1, 'cv431_7085.txt': 1, 'cv759_13522.txt': 1, 'cv454_2053.txt': 1, 'cv646_15065.txt': 1, 'cv067_19774.txt': 1, 'cv767_14062.txt': 1, 'cv866_29691.txt': 1, 'cv941_10246.txt': 1, 'cv346_18168.txt': 1, 'cv128_29627.txt': 1, 'cv214_12294.txt': 1, 'cv258_5792.txt': 1, 'cv027_25219.txt': 1, 'cv835_19159.txt': 1, 'cv123_11182.txt': 1, 'cv120_4111.txt': 1, 'cv336_10143.txt': 1, 'cv064_24576.txt': 1, 'cv148_16345.txt': 1, 'cv893_26269.txt': 1, 'cv676_21090.txt': 1, 'cv698_15253.txt': 1, 'cv041_21113.txt': 1, 'cv582_6559.txt': 1, 'cv876_9390.txt': 1, 'cv822_20049.txt': 1, 'cv113_23102.txt': 1, 'cv811_21386.txt': 1, 'cv555_23922.txt': 1, 'cv388_12009.txt': 1, 'cv574_22156.txt': 1, 'cv022_12864.txt': 1, 'cv607_7717.txt': 1, 'cv684_11798.txt': 1, 'cv263_19259.txt': 1, 'cv013_10159.txt': 1, 'cv252_23779.txt': 1, 'cv514_11187.txt': 1, 'cv463_10343.txt': 1, 'cv553_26915.txt': 1, 'cv357_13156.txt': 1, 'cv335_14665.txt': 1, 'cv096_11474.txt': 1, 'cv438_8043.txt': 1, 'cv133_16336.txt': 1, 'cv942_17082.txt': 1, 'cv997_5046.txt': 1, 'cv218_24352.txt': 1, 'cv107_24319.txt': 1, 'cv256_14740.txt': 1, 'cv433_10144.txt': 1, 'cv542_18980.txt': 1, 'cv201_6997.txt': 1, 'cv992_11962.txt': 1, 'cv897_10837.txt': 1, 'cv425_8250.txt': 1, 'cv826_11834.txt': 1, 'cv341_24430.txt': 1, 'cv735_18801.txt': 1, 'cv350_20670.txt': 1, 'cv691_5043.txt': 1, 'cv931_17563.txt': 1, 'cv829_20289.txt': 1, 'cv836_12968.txt': 1, 'cv446_11353.txt': 1, 'cv769_8123.txt': 1, 'cv505_12090.txt': 1, 'cv313_18198.txt': 1, 'cv423_11155.txt': 1, 'cv943_22488.txt': 1, 'cv855_20661.txt': 1, 'cv802_28664.txt': 1, 'cv909_9960.txt': 1, 'cv945_12160.txt': 1, 'cv261_10954.txt': 1, 'cv295_15570.txt': 1, 'cv428_11347.txt': 1, 'cv475_21692.txt': 1, 'cv257_10975.txt': 1, 'cv366_10221.txt': 1, 'cv610_2287.txt': 1, 'cv167_16376.txt': 1, 'cv076_24945.txt': 1, 'cv322_20318.txt': 1, 'cv669_22995.txt': 1, 'cv801_25228.txt': 1, 'cv191_29719.txt': 1, 'cv764_11739.txt': 1, 'cv124_4122.txt': 1, 'cv834_22195.txt': 1, 'cv196_29027.txt': 1, 'cv819_9364.txt': 1, 'cv978_20929.txt': 1, 'cv827_18331.txt': 1, 'cv993_29737.txt': 1, 'cv877_29274.txt': 1, 'cv354_8132.txt': 1, 'cv550_22211.txt': 1, 'cv783_13227.txt': 1, 'cv241_23130.txt': 1, 'cv562_10359.txt': 1, 'cv522_5583.txt': 1, 'cv934_19027.txt': 1, 'cv967_5788.txt': 1, 'cv472_29280.txt': 1, 'cv884_13632.txt': 1, 'cv320_9530.txt': 1, 'cv131_10713.txt': 1, 'cv799_18543.txt': 1, 'cv556_14808.txt': 1, 'cv039_6170.txt': 1, 'cv100_11528.txt': 1, 'cv642_29867.txt': 1, 'cv593_10987.txt': 1, 'cv800_12368.txt': 1, 'cv271_13837.txt': 1, 'cv119_9867.txt': 1, 'cv377_7946.txt': 1, 'cv551_10565.txt': 1, 'cv796_15782.txt': 1, 'cv266_25779.txt': 1, 'cv948_24606.txt': 1, 'cv538_28667.txt': 1, 'cv398_15537.txt': 1, 'cv468_15228.txt': 1, 'cv016_4659.txt': 1, 'cv086_18371.txt': 1, 'cv369_12886.txt': 1, 'cv144_5007.txt': 1, 'cv220_29059.txt': 1, 'cv339_21119.txt': 1, 'cv471_16858.txt': 1, 'cv031_18452.txt': 1, 'cv409_29786.txt': 1, 'cv708_28729.txt': 1, 'cv892_17576.txt': 1, 'cv430_17351.txt': 1, 'cv344_5312.txt': 1, 'cv963_6895.txt': 1, 'cv007_4968.txt': 1, 'cv487_10446.txt': 1, 'cv620_24265.txt': 1, 'cv525_16122.txt': 1, 'cv733_9839.txt': 1, 'cv960_29007.txt': 1, 'cv264_12801.txt': 1, 'cv247_13142.txt': 1, 'cv988_18740.txt': 1, 'cv436_19179.txt': 1, 'cv898_14187.txt': 1, 'cv720_5389.txt': 1, 'cv292_7282.txt': 1, 'cv260_13959.txt': 1, 'cv766_7540.txt': 1, 'cv989_15824.txt': 1, 'cv447_27332.txt': 1, 'cv965_26071.txt': 1, 'cv501_11657.txt': 1, 'cv244_21649.txt': 1, 'cv442_13846.txt': 1, 'cv143_19666.txt': 1, 'cv889_21430.txt': 1, 'cv896_16071.txt': 1, 'cv265_10814.txt': 1, 'cv856_29013.txt': 1, 'cv146_18458.txt': 1, 'cv239_3385.txt': 1, 'cv743_15449.txt': 1, 'cv248_13987.txt': 1, 'cv404_20315.txt': 1, 'cv847_1941.txt': 1, 'cv786_22497.txt': 1, 'cv206_14293.txt': 1, 'cv867_16661.txt': 1, 'cv816_13655.txt': 1, 'cv791_16302.txt': 1, 'cv334_10001.txt': 1, 'cv165_22619.txt': 1, 'cv790_14600.txt': 1, 'cv485_26649.txt': 1, 'cv986_13527.txt': 1, 'cv230_7428.txt': 1, 'cv543_5045.txt': 1, 'cv074_6875.txt': 1, 'cv094_27889.txt': 1, 'cv859_14107.txt': 1, 'cv844_12690.txt': 1, 'cv393_29327.txt': 1, 'cv858_18819.txt': 1, 'cv183_18612.txt': 1, 'cv029_18643.txt': 1, 'cv585_22496.txt': 1, 'cv660_21893.txt': 1, 'cv529_10420.txt': 1, 'cv150_12916.txt': 1, 'cv930_13475.txt': 1, 'cv134_22246.txt': 1, 'cv457_18453.txt': 1, 'cv452_5088.txt': 1, 'cv842_5866.txt': 1, 'cv742_7751.txt': 1, 'cv095_28892.txt': 1, 'cv519_14661.txt': 1, 'cv991_18645.txt': 1, 'cv267_14952.txt': 1, 'cv484_25054.txt': 1, 'cv228_5806.txt': 1, 'cv982_21103.txt': 1, 'cv662_13320.txt': 1, 'cv726_4719.txt': 1, 'cv085_1381.txt': 1, 'cv675_21588.txt': 1, 'cv084_13566.txt': 1, 'cv429_7439.txt': 1, 'cv852_27523.txt': 1, 'cv567_29611.txt': 1, 'cv507_9220.txt': 1, 'cv815_22456.txt': 1, 'cv330_29809.txt': 1, 'cv902_12256.txt': 1, 'cv193_5416.txt': 1, 'cv333_8916.txt': 1, 'cv326_13295.txt': 1, 'cv342_19456.txt': 1, 'cv862_14324.txt': 1, 'cv780_7984.txt': 1, 'cv869_23611.txt': 1, 'cv916_15467.txt': 1, 'cv049_20471.txt': 1, 'cv151_15771.txt': 1, 'cv302_25649.txt': 1, 'cv871_24888.txt': 1, 'cv199_9629.txt': 1, 'cv936_15954.txt': 1, 'cv097_24970.txt': 1, 'cv103_11021.txt': 1, 'cv577_28549.txt': 1, 'cv025_3108.txt': 1, 'cv298_23111.txt': 1, 'cv164_22447.txt': 1, 'cv010_29198.txt': 1, 'cv693_18063.txt': 1, 'cv622_8147.txt': 1, 'cv547_16324.txt': 1, 'cv630_10057.txt': 1, 'cv782_19526.txt': 1, 'cv470_15952.txt': 1, 'cv806_8842.txt': 1, 'cv976_10267.txt': 1, 'cv823_15569.txt': 1, 'cv692_15451.txt': 1, 'cv358_10691.txt': 1, 'cv345_9954.txt': 1, 'cv279_18329.txt': 1, 'cv149_15670.txt': 1, 'cv138_12721.txt': 1, 'cv063_28997.txt': 1, 'cv821_29364.txt': 1, 'cv906_11491.txt': 1, 'cv332_16307.txt': 1, 'cv560_17175.txt': 1, 'cv359_6647.txt': 1, 'cv812_17924.txt': 1, 'cv137_15422.txt': 1, 'cv515_17069.txt': 1, 'cv851_20469.txt': 1, 'cv079_11933.txt': 1, 'cv106_16807.txt': 1, 'cv092_28017.txt': 1, 'cv640_5378.txt': 1, 'cv053_21822.txt': 1, 'cv121_17302.txt': 1, 'cv225_29224.txt': 1, 'cv283_11055.txt': 1, 'cv204_8451.txt': 1, 'cv251_22636.txt': 1, 'cv162_10424.txt': 1, 'cv715_18179.txt': 1, 'cv874_11236.txt': 1, 'cv697_11162.txt': 1, 'cv376_19435.txt': 1, 'cv944_13521.txt': 1, 'cv709_10529.txt': 1, 'cv689_12587.txt': 1, 'cv448_14695.txt': 1, 'cv156_10481.txt': 1, 'cv619_12462.txt': 1, 'cv002_15918.txt': 1, 'cv627_11620.txt': 1, 'cv259_10934.txt': 1, 'cv845_14290.txt': 1, 'cv548_17731.txt': 1, 'cv416_11136.txt': 1, 'cv003_11664.txt': 1, 'cv731_4136.txt': 1, 'cv848_10036.txt': 1, 'cv284_19119.txt': 1, 'cv421_9709.txt': 1, 'cv672_28083.txt': 1, 'cv723_8648.txt': 1, 'cv592_22315.txt': 1, 'cv700_21947.txt': 1, 'cv750_10180.txt': 1, 'cv951_10926.txt': 1, 'cv495_14518.txt': 1, 'cv061_8837.txt': 1, 'cv135_11603.txt': 1, 'cv145_11472.txt': 1, 'cv512_15965.txt': 1, 'cv412_24095.txt': 1, 'cv051_10306.txt': 1, 'cv661_2450.txt': 1, 'cv077_22138.txt': 1, 'cv725_10103.txt': 1, 'cv546_11767.txt': 1, 'cv070_12289.txt': 1, 'cv770_10451.txt': 1, 'cv042_10982.txt': 1, 'cv116_28942.txt': 1, 'cv710_22577.txt': 1, 'cv694_4876.txt': 1, 'cv368_10466.txt': 1, 'cv707_10678.txt': 1, 'cv580_14064.txt': 1, 'cv414_10518.txt': 1, 'cv864_3416.txt': 1, 'cv795_10122.txt': 1, 'cv465_22431.txt': 1, 'cv140_7479.txt': 1, 'cv190_27052.txt': 1, 'cv435_23110.txt': 1, 'cv274_25253.txt': 1, 'cv221_2695.txt': 1, 'cv126_28971.txt': 1, 'cv637_1250.txt': 1, 'cv189_22934.txt': 1, 'cv426_10421.txt': 1, 'cv654_18246.txt': 1, 'cv192_14395.txt': 1, 'cv716_10514.txt': 1, 'cv460_10842.txt': 1, 'cv681_9692.txt': 1, 'cv732_12245.txt': 1, 'cv141_15686.txt': 1, 'cv163_10052.txt': 1, 'cv724_13681.txt': 1, 'cv949_20112.txt': 1, 'cv854_17740.txt': 1, 'cv558_29507.txt': 1, 'cv980_10953.txt': 1, 'cv846_29497.txt': 1, 'cv613_21796.txt': 1, 'cv883_27751.txt': 1, 'cv321_12843.txt': 1, 'cv602_8300.txt': 1, 'cv664_4389.txt': 1, 'cv659_19944.txt': 1, 'cv977_4938.txt': 1, 'cv663_13019.txt': 1, 'cv168_7050.txt': 1, 'cv445_25882.txt': 1, 'cv222_17395.txt': 1, 'cv983_22928.txt': 1, 'cv091_7400.txt': 1, 'cv399_2877.txt': 1, 'cv853_29233.txt': 1, 'cv920_29622.txt': 1, 'cv521_15828.txt': 1, 'cv814_18975.txt': 1, 'cv212_10027.txt': 1, 'cv658_10532.txt': 1, 'cv674_10732.txt': 1, 'cv481_7436.txt': 1, 'cv632_9610.txt': 1, 'cv187_12829.txt': 1, 'cv837_27325.txt': 1, 'cv173_4471.txt': 1, 'cv903_17822.txt': 1, 'cv130_17083.txt': 1, 'cv420_28795.txt': 1, 'cv275_28887.txt': 1, 'cv531_26486.txt': 1, 'cv194_12079.txt': 1, 'cv072_6169.txt': 1, 'cv405_20399.txt': 1, 'cv408_5297.txt': 1, 'cv083_24234.txt': 1, 'cv493_12839.txt': 1, 'cv226_2618.txt': 1, 'cv329_29370.txt': 1, 'cv516_11172.txt': 1, 'cv056_13133.txt': 1, 'cv831_14689.txt': 1, 'cv905_29114.txt': 1, 'cv648_15792.txt': 1, 'cv940_17705.txt': 1, 'cv749_17765.txt': 1, 'cv849_15729.txt': 1, 'cv021_15838.txt': 1, 'cv170_3006.txt': 1, 'cv666_18963.txt': 1, 'cv690_5619.txt': 1, 'cv362_15341.txt': 1, 'cv572_18657.txt': 1, 'cv778_17330.txt': 1, 'cv917_29715.txt': 1, 'cv255_13683.txt': 1, 'cv269_21732.txt': 1, 'cv372_6552.txt': 1, 'cv385_29741.txt': 1, 'cv473_7367.txt': 1, 'cv861_1198.txt': 1, 'cv958_12162.txt': 1, 'cv611_21120.txt': 1, 'cv017_22464.txt': 1, 'cv536_27134.txt': 1, 'cv589_12064.txt': 1, 'cv621_14368.txt': 1, 'cv744_10038.txt': 1, 'cv312_29377.txt': 1, 'cv314_14422.txt': 1, 'cv122_7392.txt': 1, 'cv340_13287.txt': 1, 'cv773_18817.txt': 1, 'cv526_12083.txt': 1, 'cv999_13106.txt': 1, 'cv987_6965.txt': 1, 'cv185_28654.txt': 1, 'cv612_5461.txt': 1, 'cv533_9821.txt': 1, 'cv169_23778.txt': 1, 'cv506_15956.txt': 1, 'cv365_11576.txt': 1, 'cv112_11193.txt': 1, 'cv386_10080.txt': 1, 'cv129_16741.txt': 1, 'cv950_12350.txt': 1, 'cv857_15958.txt': 1, 'cv048_16828.txt': 1, 'cv182_7281.txt': 1, 'cv175_6964.txt': 1, 'cv838_24728.txt': 1, 'cv503_10558.txt': 1, 'cv455_29000.txt': 1, 'cv035_3954.txt': 1, 'cv751_15719.txt': 1, 'cv713_29155.txt': 1, 'cv281_23253.txt': 1, 'cv101_10175.txt': 1, 'cv583_29692.txt': 1, 'cv202_10654.txt': 1, 'cv809_5009.txt': 1, 'cv568_15638.txt': 1, 'cv863_7424.txt': 1, 'cv437_22849.txt': 1, 'cv763_14729.txt': 1, 'cv328_10373.txt': 1, 'cv347_13194.txt': 1, 'cv933_23776.txt': 1, 'cv384_17140.txt': 1, 'cv203_17986.txt': 1, 'cv005_29443.txt': 1, 'cv066_10821.txt': 1, 'cv966_28832.txt': 1, 'cv554_13151.txt': 1, 'cv343_10368.txt': 1, 'cv509_15888.txt': 1, 'cv775_16237.txt': 1, 'cv623_15356.txt': 1, 'cv419_13394.txt': 1, 'cv925_8969.txt': 1, 'cv280_8267.txt': 1, 'cv062_23115.txt': 1, 'cv052_29378.txt': 1, 'cv011_12166.txt': 1, 'cv276_15684.txt': 1, 'cv054_4230.txt': 1, 'cv499_10658.txt': 1, 'cv038_9749.txt': 1, 'cv737_28907.txt': 1, 'cv316_6370.txt': 1, 'cv907_3541.txt': 1, 'cv047_1754.txt': 1, 'cv830_6014.txt': 1, 'cv605_11800.txt': 1, 'cv488_19856.txt': 1, 'cv865_2895.txt': 1, 'cv294_11684.txt': 1, 'cv787_13743.txt': 1, 'cv015_29439.txt': 1, 'cv603_17694.txt': 1, 'cv714_18502.txt': 1, 'cv233_15964.txt': 1, 'cv517_19219.txt': 1, 'cv959_14611.txt': 1, 'cv649_12735.txt': 1, 'cv291_26635.txt': 1, 'cv296_12251.txt': 1, 'cv932_13401.txt': 1, 'cv434_5793.txt': 1, 'cv285_16494.txt': 1, 'cv030_21593.txt': 1, 'cv717_15953.txt': 1, 'cv397_29023.txt': 1, 'cv287_15900.txt': 1, 'cv929_16908.txt': 1, 'cv590_19290.txt': 1, 'cv361_28944.txt': 1, 'cv882_10026.txt': 1, 'cv370_5221.txt': 1, 'cv705_11059.txt': 1, 'cv774_13845.txt': 1, 'cv245_8569.txt': 1, 'cv104_18134.txt': 1, 'cv880_29800.txt': 1, 'cv174_9659.txt': 1, 'cv968_24218.txt': 1, 'cv532_6522.txt': 1, 'cv001_18431.txt': 1, 'cv820_22892.txt': 1, 'cv401_12605.txt': 1, 'cv798_23531.txt': 1, 'cv459_20319.txt': 1, 'cv788_25272.txt': 1, 'cv911_20260.txt': 1, 'cv840_16321.txt': 1, 'cv102_7846.txt': 1, 'cv739_11209.txt': 1, 'cv387_11507.txt': 1, 'cv921_12747.txt': 1, 'cv374_25436.txt': 1, 'cv979_18921.txt': 1, 'cv301_12146.txt': 1, 'cv996_11592.txt': 1, 'cv458_8604.txt': 1, 'cv677_17715.txt': 1, 'cv178_12972.txt': 1, 'cv308_5016.txt': 1, 'cv023_12672.txt': 1, 'cv807_21740.txt': 1, 'cv114_18398.txt': 1, 'cv712_22920.txt': 1, 'cv109_21172.txt': 1, 'cv524_23627.txt': 1, 'cv355_16413.txt': 1, 'cv881_13254.txt': 1, 'cv755_23616.txt': 1, 'cv765_19037.txt': 1, 'cv638_2953.txt': 1, 'cv885_12318.txt': 1, 'cv478_14309.txt': 1, 'cv232_14991.txt': 1, 'cv040_8276.txt': 1, 'cv828_19831.txt': 1, 'cv886_18177.txt': 1, 'cv990_11591.txt': 1, 'cv360_8398.txt': 1, 'cv901_11017.txt': 1, 'cv424_8831.txt': 1, 'cv868_11948.txt': 1, 'cv596_28311.txt': 1, 'cv682_16139.txt': 1, 'cv439_15970.txt': 1, 'cv938_10220.txt': 1, 'cv195_14528.txt': 1, 'cv914_28742.txt': 1, 'cv353_18159.txt': 1, 'cv688_7368.txt': 1, 'cv311_16002.txt': 1, 'cv953_6836.txt': 1, 'cv784_14394.txt': 1, 'cv541_28835.txt': 1, 'cv403_6621.txt': 1, 'cv093_13951.txt': 1, 'cv262_12649.txt': 1, 'cv009_29592.txt': 1, 'cv818_10211.txt': 1, 'cv600_23878.txt': 1, 'cv616_29319.txt': 1, 'cv456_18985.txt': 1, 'cv117_24295.txt': 1, 'cv422_9381.txt': 1, 'cv895_21022.txt': 1, 'cv633_29837.txt': 1, 'cv356_25163.txt': 1, 'cv928_9168.txt': 1, 'cv080_13465.txt': 1, 'cv520_12295.txt': 1, 'cv413_7398.txt': 1, 'cv618_8974.txt': 1, 'cv483_16378.txt': 1, 'cv317_24049.txt': 1, 'cv667_18467.txt': 1, 'cv631_4967.txt': 1, 'cv973_10066.txt': 1, 'cv210_9312.txt': 1, 'cv389_9369.txt': 1, 'cv415_22517.txt': 1, 'cv371_7630.txt': 1, 'cv789_12136.txt': 1, 'cv617_9322.txt': 1, 'cv019_14482.txt': 1, 'cv926_17059.txt': 1, 'cv286_25050.txt': 1, 'cv758_9671.txt': 1, 'cv004_11636.txt': 1, 'cv396_17989.txt': 1, 'cv843_15544.txt': 1, 'cv186_2269.txt': 1, 'cv754_7216.txt': 1, 'cv075_6500.txt': 1, 'cv721_29121.txt': 1, 'cv711_11665.txt': 1, 'cv718_11434.txt': 1, 'cv655_11154.txt': 1, 'cv118_28980.txt': 1, 'cv310_13091.txt': 1, 'cv014_13924.txt': 1, 'cv636_15279.txt': 1, 'cv227_24215.txt': 1, 'cv954_18628.txt': 1, 'cv032_22550.txt': 1, 'cv597_26360.txt': 1, 'cv741_11890.txt': 1, 'cv899_16014.txt': 1, 'cv159_29505.txt': 1, 'cv981_14989.txt': 1, 'cv650_14340.txt': 1, 'cv242_10638.txt': 1, 'cv586_7543.txt': 1, 'cv249_11640.txt': 1, 'cv462_19350.txt': 1, 'cv461_19600.txt': 1, 'cv634_11101.txt': 1, 'cv476_16856.txt': 1, 'cv578_15094.txt': 1, 'cv539_20347.txt': 1, 'cv482_10580.txt': 1, 'cv179_9228.txt': 1, 'cv947_10601.txt': 1, 'cv059_28885.txt': 1, 'cv045_23923.txt': 1, 'cv740_12445.txt': 1, 'cv729_10154.txt': 1, 'cv875_5754.txt': 1, 'cv523_16615.txt': 1, 'cv081_16582.txt': 1, 'cv235_10217.txt': 1, 'cv972_26417.txt': 1, 'cv307_25270.txt': 1, 'cv089_11418.txt': 1, 'cv197_29328.txt': 1, 'cv703_16143.txt': 1, 'cv939_10583.txt': 1, 'cv745_12773.txt': 1, 'cv670_25826.txt': 1, 'cv566_8581.txt': 1, 'cv060_10844.txt': 1, 'cv125_9391.txt': 1, 'cv564_11110.txt': 1, 'cv792_3832.txt': 1, 'cv327_20292.txt': 1, 'cv082_11080.txt': 1, 'cv887_5126.txt': 1, 'cv817_4041.txt': 1, 'cv392_11458.txt': 1, 'cv132_5618.txt': 1, 'cv496_10530.txt': 1, 'cv535_19728.txt': 1, 'cv668_17604.txt': 1, 'cv888_24435.txt': 1, 'cv105_17990.txt': 1, 'cv971_10874.txt': 1, 'cv641_12349.txt': 1, 'cv243_20728.txt': 1, 'cv530_16212.txt': 1, 'cv443_21118.txt': 1, 'cv652_13972.txt': 1, 'cv180_16113.txt': 1, 'cv508_16006.txt': 1, 'cv683_12167.txt': 1, 'cv037_18510.txt': 1, 'cv136_11505.txt': 1, 'cv995_21821.txt': 1, 'cv747_16556.txt': 1, 'cv779_17881.txt': 1, 'cv594_11039.txt': 1, 'cv872_12591.txt': 1, 'cv606_15985.txt': 1, 'cv561_9201.txt': 1, 'cv110_27788.txt': 1, 'cv068_13400.txt': 1, 'cv108_15571.txt': 1, 'cv394_5137.txt': 1, 'cv288_18791.txt': 1, 'cv912_5674.txt': 1, 'cv591_23640.txt': 1, 'cv006_15448.txt': 1, 'cv466_18722.txt': 1, 'cv679_28559.txt': 1, 'cv441_13711.txt': 1, 'cv318_10493.txt': 1, 'cv299_16214.txt': 1, 'cv411_15007.txt': 1, 'cv935_23841.txt': 1, 'cv417_13115.txt': 1, 'cv757_10189.txt': 1, 'cv304_28706.txt': 1, 'cv073_21785.txt': 1, 'cv626_7410.txt': 1, 'cv573_29525.txt': 1, 'cv771_28665.txt': 1, 'cv565_29572.txt': 1, 'cv761_12620.txt': 1, 'cv628_19325.txt': 1, 'cv673_24714.txt': 1, 'cv486_9799.txt': 1, 'cv584_29722.txt': 1, 'cv142_22516.txt': 1, 'cv127_14711.txt': 1, 'cv300_22284.txt': 1, 'cv349_13507.txt': 1, 'cv752_24155.txt': 1, 'cv653_19583.txt': 1, 'cv651_10492.txt': 1, 'cv824_8838.txt': 1, 'cv351_15458.txt': 1, 'cv400_19220.txt': 1, 'cv730_10279.txt': 1, 'cv894_2068.txt': 1, 'cv364_12901.txt': 1, 'cv338_8821.txt': 1, 'cv696_29740.txt': 1, 'cv379_21963.txt': 1, 'cv402_14425.txt': 1, 'cv746_10147.txt': 1, 'cv046_10188.txt': 1, 'cv797_6957.txt': 1, 'cv924_29540.txt': 1, 'cv974_22941.txt': 1, 'cv922_10073.txt': 1, 'cv984_12767.txt': 1, 'cv184_2673.txt': 1, 'cv008_29435.txt': 1, 'cv231_10425.txt': 1, 'cv860_13853.txt': 1, 'cv961_5682.txt': 1, 'cv012_29576.txt': 1, 'cv722_7110.txt': 1, 'cv323_29805.txt': 1, 'cv678_13419.txt': 1, 'cv890_3977.txt': 1, 'cv246_28807.txt': 1, 'cv537_12370.txt': 1, 'cv273_29112.txt': 1, 'cv900_10331.txt': 1, 'cv050_11175.txt': 1, 'cv200_2915.txt': 1, 'cv608_23231.txt': 1, 'cv406_21020.txt': 1, 'cv704_15969.txt': 1, 'cv502_10406.txt': 1, 'cv643_29349.txt': 1, 'cv036_16831.txt': 1, 'cv305_9946.txt': 1, 'cv738_10116.txt': 1, 'cv833_11053.txt': 1, 'cv923_11051.txt': 1, 'cv728_16133.txt': 1, 'cv207_29284.txt': 1, 'cv324_7082.txt': 1, 'cv309_22571.txt': 1, 'cv615_14182.txt': 1, 'cv380_7574.txt': 1, 'cv069_10801.txt': 1, 'cv325_16629.txt': 1, 'cv504_29243.txt': 1, 'cv240_14336.txt': 1, 'cv964_6021.txt': 1, 'cv970_18450.txt': 1, 'cv020_8825.txt': 1, 'cv528_10822.txt': 1, 'cv373_20404.txt': 1, 'cv297_10047.txt': 1, 'cv153_10779.txt': 1, 'cv177_10367.txt': 1, 'cv687_21100.txt': 1, 'cv171_13537.txt': 1, 'cv910_20488.txt': 1, 'cv772_12119.txt': 1, 'cv569_26381.txt': 1, 'cv213_18934.txt': 1, 'cv671_5054.txt': 1, 'cv768_11751.txt': 1, 'cv277_19091.txt': 1, 'cv205_9457.txt': 1, 'cv919_16380.txt': 1, 'cv527_10123.txt': 1, 'cv272_18974.txt': 1, 'cv598_16452.txt': 1, 'cv975_10981.txt': 1, 'cv211_9953.txt': 1, 'cv805_19601.txt': 1, 'cv985_6359.txt': 1, 'cv319_14727.txt': 1, 'cv236_11565.txt': 1, 'cv088_24113.txt': 1, 'cv270_6079.txt': 1, 'cv575_21150.txt': 1, 'cv099_10534.txt': 1, 'cv444_9974.txt': 1, 'cv492_18271.txt': 1, 'cv224_17661.txt': 1, 'cv087_1989.txt': 1, 'cv552_10016.txt': 1, 'cv223_29066.txt': 1, 'cv870_16348.txt': 1, 'cv352_5524.txt': 1, 'cv024_6778.txt': 1, 'cv208_9020.txt': 1, 'cv604_2230.txt': 1, 'cv467_25773.txt': 1, 'cv176_12857.txt': 1, 'cv479_5649.txt': 1, 'cv927_10681.txt': 1, 'cv427_10825.txt': 1, 'cv571_29366.txt': 1, 'cv418_14774.txt': 1, 'cv587_19162.txt': 1, 'cv557_11449.txt': 1, 'cv776_20529.txt': 1, 'cv453_10379.txt': 1, 'cv793_13650.txt': 1, 'cv639_10308.txt': 1, 'cv559_0050.txt': 1, 'cv155_7308.txt': 1, 'cv918_2693.txt': 1, 'cv753_10875.txt': 1, 'cv635_10022.txt': 1, 'cv058_8025.txt': 1, 'cv513_6923.txt': 1, 'cv706_24716.txt': 1, 'cv808_12635.txt': 1, 'cv727_4978.txt': 1, 'cv702_11500.txt': 1, 'cv071_12095.txt': 1, 'cv337_29181.txt': 1, 'cv474_10209.txt': 1, 'cv803_8207.txt': 1, 'cv018_20137.txt': 1, 'cv315_11629.txt': 1, 'cv629_14909.txt': 1, 'cv952_25240.txt': 1, 'cv850_16466.txt': 1, 'cv057_7453.txt': 1, 'cv946_18658.txt': 1, 'cv268_18834.txt': 1, 'cv534_14083.txt': 1, 'cv879_14903.txt': 1, 'cv825_5063.txt': 1, 'cv699_7223.txt': 1, 'cv760_8597.txt': 1, 'cv378_20629.txt': 1, 'cv480_19817.txt': 1, 'cv282_6653.txt': 1, 'cv464_15650.txt': 1, 'cv841_3967.txt': 1, 'cv229_13611.txt': 1, 'cv614_10626.txt': 1, 'cv450_7890.txt': 1, 'cv238_12931.txt': 1, 'cv736_23670.txt': 1, 'cv111_11473.txt': 1, 'cv540_3421.txt': 1, 'cv500_10251.txt': 1, 'cv395_10849.txt': 1, 'cv390_11345.txt': 1, 'cv873_18636.txt': 1, 'cv609_23877.txt': 1, 'cv599_20988.txt': 1, 'cv065_15248.txt': 1, 'cv043_15013.txt': 1, 'cv181_14401.txt': 1, 'cv303_27520.txt': 1, 'cv158_10390.txt': 1, 'cv957_8737.txt': 1, 'cv498_8832.txt': 1, 'cv804_10862.txt': 1, 'cv115_25396.txt': 1, 'cv254_6027.txt': 1, 'cv576_14094.txt': 1, 'cv033_24444.txt': 1, 'cv588_13008.txt': 1, 'cv734_21568.txt': 1, 'cv491_12145.txt': 1, 'cv647_13691.txt': 1, 'cv665_29538.txt': 1}\n",
      "{'cv676_22202.txt': -1, 'cv839_22807.txt': -1, 'cv155_7845.txt': -1, 'cv465_23401.txt': -1, 'cv398_17047.txt': -1, 'cv206_15893.txt': -1, 'cv037_19798.txt': -1, 'cv279_19452.txt': -1, 'cv646_16817.txt': -1, 'cv756_23676.txt': -1, 'cv823_17055.txt': -1, 'cv747_18189.txt': -1, 'cv258_5627.txt': -1, 'cv948_25870.txt': -1, 'cv744_10091.txt': -1, 'cv754_7709.txt': -1, 'cv838_25886.txt': -1, 'cv131_11568.txt': -1, 'cv401_13758.txt': -1, 'cv523_18285.txt': -1, 'cv073_23039.txt': -1, 'cv688_7884.txt': -1, 'cv664_4264.txt': -1, 'cv461_21124.txt': -1, 'cv909_9973.txt': -1, 'cv939_11247.txt': -1, 'cv368_11090.txt': -1, 'cv185_28372.txt': -1, 'cv749_18960.txt': -1, 'cv836_14311.txt': -1, 'cv322_21820.txt': -1, 'cv789_12991.txt': -1, 'cv617_9561.txt': -1, 'cv288_20212.txt': -1, 'cv464_17076.txt': -1, 'cv904_25663.txt': -1, 'cv866_29447.txt': -1, 'cv429_7937.txt': -1, 'cv212_10054.txt': -1, 'cv007_4992.txt': -1, 'cv522_5418.txt': -1, 'cv109_22599.txt': -1, 'cv753_11812.txt': -1, 'cv312_29308.txt': -1, 'cv294_12695.txt': -1, 'cv886_19210.txt': -1, 'cv479_5450.txt': -1, 'cv867_18362.txt': -1, 'cv260_15652.txt': -1, 'cv313_19337.txt': -1, 'cv317_25111.txt': -1, 'cv506_17521.txt': -1, 'cv602_8830.txt': -1, 'cv710_23745.txt': -1, 'cv971_11790.txt': -1, 'cv098_17021.txt': -1, 'cv960_28877.txt': -1, 'cv423_12089.txt': -1, 'cv887_5306.txt': -1, 'cv291_26844.txt': -1, 'cv049_21917.txt': -1, 'cv382_8393.txt': -1, 'cv915_9342.txt': -1, 'cv217_28707.txt': -1, 'cv729_10475.txt': -1, 'cv862_15924.txt': -1, 'cv034_29446.txt': -1, 'cv560_18608.txt': -1, 'cv684_12727.txt': -1, 'cv627_12603.txt': -1, 'cv498_9288.txt': -1, 'cv044_18429.txt': -1, 'cv359_6751.txt': -1, 'cv537_13516.txt': -1, 'cv089_12222.txt': -1, 'cv784_16077.txt': -1, 'cv801_26335.txt': -1, 'cv692_17026.txt': -1, 'cv531_26838.txt': -1, 'cv913_29127.txt': -1, 'cv319_16459.txt': -1, 'cv377_8440.txt': -1, 'cv943_23547.txt': -1, 'cv691_5090.txt': -1, 'cv604_23339.txt': -1, 'cv327_21743.txt': -1, 'cv718_12227.txt': -1, 'cv686_15553.txt': -1, 'cv195_16146.txt': -1, 'cv170_29808.txt': -1, 'cv254_5870.txt': -1, 'cv435_24355.txt': -1, 'cv184_26935.txt': -1, 'cv388_12810.txt': -1, 'cv835_20531.txt': -1, 'cv541_28683.txt': -1, 'cv609_25038.txt': -1, 'cv708_28539.txt': -1, 'cv386_10229.txt': -1, 'cv392_12238.txt': -1, 'cv822_21545.txt': -1, 'cv758_9740.txt': -1, 'cv819_9567.txt': -1, 'cv704_17622.txt': -1, 'cv458_9000.txt': -1, 'cv679_28221.txt': -1, 'cv097_26081.txt': -1, 'cv740_13643.txt': -1, 'cv773_20264.txt': -1, 'cv600_25043.txt': -1, 'cv416_12048.txt': -1, 'cv702_12371.txt': -1, 'cv527_10338.txt': -1, 'cv055_8926.txt': -1, 'cv798_24779.txt': -1, 'cv371_8197.txt': -1, 'cv549_22771.txt': -1, 'cv283_11963.txt': -1, 'cv430_18662.txt': -1, 'cv921_13988.txt': -1, 'cv730_10729.txt': -1, 'cv107_25639.txt': -1, 'cv705_11973.txt': -1, 'cv421_9752.txt': -1, 'cv447_27334.txt': -1, 'cv739_12179.txt': -1, 'cv240_15948.txt': -1, 'cv122_7891.txt': -1, 'cv460_11723.txt': -1, 'cv893_26731.txt': -1, 'cv234_22123.txt': -1, 'cv803_8584.txt': -1, 'cv379_23167.txt': -1, 'cv198_19313.txt': -1, 'cv556_16563.txt': -1, 'cv632_9704.txt': -1, 'cv853_29119.txt': -1, 'cv023_13847.txt': -1, 'cv410_25624.txt': -1, 'cv490_18986.txt': -1, 'cv755_24881.txt': -1, 'cv930_14949.txt': -1, 'cv645_17078.txt': -1, 'cv497_27086.txt': -1, 'cv876_9633.txt': -1, 'cv841_3367.txt': -1, 'cv318_11146.txt': -1, 'cv189_24248.txt': -1, 'cv888_25678.txt': -1, 'cv210_9557.txt': -1, 'cv815_23466.txt': -1, 'cv227_25406.txt': -1, 'cv748_14044.txt': -1, 'cv667_19672.txt': -1, 'cv437_24070.txt': -1, 'cv988_20168.txt': -1, 'cv027_26270.txt': -1, 'cv918_27080.txt': -1, 'cv768_12709.txt': -1, 'cv036_18385.txt': -1, 'cv938_10706.txt': -1, 'cv362_16985.txt': -1, 'cv849_17215.txt': -1, 'cv144_5010.txt': -1, 'cv320_9693.txt': -1, 'cv492_19370.txt': -1, 'cv112_12178.txt': -1, 'cv558_29376.txt': -1, 'cv141_17179.txt': -1, 'cv168_7435.txt': -1, 'cv944_15042.txt': -1, 'cv308_5079.txt': -1, 'cv752_25330.txt': -1, 'cv356_26170.txt': -1, 'cv738_10287.txt': -1, 'cv731_3968.txt': -1, 'cv519_16239.txt': -1, 'cv847_20855.txt': -1, 'cv687_22207.txt': -1, 'cv854_18955.txt': -1, 'cv050_12128.txt': -1, 'cv179_9533.txt': -1, 'cv489_19046.txt': -1, 'cv127_16451.txt': -1, 'cv496_11185.txt': -1, 'cv614_11320.txt': -1, 'cv140_7963.txt': -1, 'cv987_7394.txt': -1, 'cv851_21895.txt': -1, 'cv228_5644.txt': -1, 'cv542_20359.txt': -1, 'cv225_29083.txt': -1, 'cv063_28852.txt': -1, 'cv341_25667.txt': -1, 'cv563_18610.txt': -1, 'cv022_14227.txt': -1, 'cv520_13297.txt': -1, 'cv102_8306.txt': -1, 'cv150_14279.txt': -1, 'cv858_20266.txt': -1, 'cv936_17473.txt': -1, 'cv762_15604.txt': -1, 'cv891_6035.txt': -1, 'cv445_26683.txt': -1, 'cv946_20084.txt': -1, 'cv507_9509.txt': -1, 'cv330_29675.txt': -1, 'cv350_22139.txt': -1, 'cv837_27232.txt': -1, 'cv347_14722.txt': -1, 'cv483_18103.txt': -1, 'cv287_17410.txt': -1, 'cv777_10247.txt': -1, 'cv630_10152.txt': -1, 'cv975_11920.txt': -1, 'cv633_29730.txt': -1, 'cv028_26964.txt': -1, 'cv101_10537.txt': -1, 'cv171_15164.txt': -1, 'cv554_14678.txt': -1, 'cv963_7208.txt': -1, 'cv775_17966.txt': -1, 'cv564_12011.txt': -1, 'cv448_16409.txt': -1, 'cv681_9744.txt': -1, 'cv865_28796.txt': -1, 'cv770_11061.txt': -1, 'cv264_14108.txt': -1, 'cv650_15974.txt': -1, 'cv714_19704.txt': -1, 'cv607_8235.txt': -1, 'cv699_7773.txt': -1, 'cv205_9676.txt': -1, 'cv297_10104.txt': -1, 'cv491_12992.txt': -1, 'cv310_14568.txt': -1, 'cv475_22978.txt': -1, 'cv824_9335.txt': -1, 'cv941_10718.txt': -1, 'cv965_26688.txt': -1, 'cv176_14196.txt': -1, 'cv349_15032.txt': -1, 'cv612_5396.txt': -1, 'cv053_23117.txt': -1, 'cv040_8829.txt': -1, 'cv370_5338.txt': -1, 'cv203_19052.txt': -1, 'cv623_16988.txt': -1, 'cv937_9816.txt': -1, 'cv394_5311.txt': -1, 'cv054_4101.txt': -1, 'cv139_14236.txt': -1, 'cv134_23300.txt': -1, 'cv580_15681.txt': -1, 'cv986_15092.txt': -1, 'cv611_2253.txt': -1, 'cv816_15257.txt': -1, 'cv393_29234.txt': -1, 'cv326_14777.txt': -1, 'cv302_26481.txt': -1, 'cv010_29063.txt': -1, 'cv415_23674.txt': -1, 'cv932_14854.txt': -1, 'cv003_12683.txt': -1, 'cv962_9813.txt': -1, 'cv115_26443.txt': -1, 'cv409_29625.txt': -1, 'cv180_17823.txt': -1, 'cv502_10970.txt': -1, 'cv615_15734.txt': -1, 'cv735_20218.txt': -1, 'cv482_11233.txt': -1, 'cv324_7502.txt': -1, 'cv926_18471.txt': -1, 'cv844_13890.txt': -1, 'cv845_15886.txt': -1, 'cv257_11856.txt': -1, 'cv335_16299.txt': -1, 'cv634_11989.txt': -1, 'cv200_29006.txt': -1, 'cv192_16079.txt': -1, 'cv759_15091.txt': -1, 'cv009_29417.txt': -1, 'cv123_12165.txt': -1, 'cv024_7033.txt': -1, 'cv655_12055.txt': -1, 'cv366_10709.txt': -1, 'cv208_9475.txt': -1, 'cv931_18783.txt': -1, 'cv656_25395.txt': -1, 'cv828_21392.txt': -1, 'cv440_16891.txt': -1, 'cv146_19587.txt': -1, 'cv671_5164.txt': -1, 'cv113_24354.txt': -1, 'cv501_12675.txt': -1, 'cv493_14135.txt': -1, 'cv622_8583.txt': -1, 'cv643_29282.txt': -1, 'cv703_17948.txt': -1, 'cv121_18621.txt': -1, 'cv378_21982.txt': -1, 'cv902_13217.txt': -1, 'cv162_10977.txt': -1, 'cv922_10185.txt': -1, 'cv105_19135.txt': -1, 'cv006_17022.txt': -1, 'cv526_12868.txt': -1, 'cv390_12187.txt': -1, 'cv885_13390.txt': -1, 'cv778_18629.txt': -1, 'cv535_21183.txt': -1, 'cv088_25274.txt': -1, 'cv128_29444.txt': -1, 'cv525_17930.txt': -1, 'cv651_11120.txt': -1, 'cv905_28965.txt': -1, 'cv592_23391.txt': -1, 'cv665_29386.txt': -1, 'cv137_17020.txt': -1, 'cv534_15683.txt': -1, 'cv295_17060.txt': -1, 'cv411_16799.txt': -1, 'cv499_11407.txt': -1, 'cv782_21078.txt': -1, 'cv201_7421.txt': -1, 'cv883_27621.txt': -1, 'cv292_7804.txt': -1, 'cv282_6833.txt': -1, 'cv065_16909.txt': -1, 'cv776_21934.txt': -1, 'cv487_11058.txt': -1, 'cv969_14760.txt': -1, 'cv964_5794.txt': -1, 'cv925_9459.txt': -1, 'cv979_2029.txt': -1, 'cv553_26965.txt': -1, 'cv638_29394.txt': -1, 'cv795_10291.txt': -1, 'cv610_24153.txt': -1, 'cv725_10266.txt': -1, 'cv035_3343.txt': -1, 'cv923_11951.txt': -1, 'cv884_15230.txt': -1, 'cv352_5414.txt': -1, 'cv025_29825.txt': -1, 'cv426_10976.txt': -1, 'cv223_28923.txt': -1, 'cv074_7188.txt': -1, 'cv467_26610.txt': -1, 'cv114_19501.txt': -1, 'cv038_9781.txt': -1, 'cv296_13146.txt': -1, 'cv514_12173.txt': -1, 'cv790_16202.txt': -1, 'cv015_29356.txt': -1, 'cv547_18043.txt': -1, 'cv270_5873.txt': -1, 'cv529_10972.txt': -1, 'cv485_26879.txt': -1, 'cv736_24947.txt': -1, 'cv271_15364.txt': -1, 'cv289_6239.txt': -1, 'cv344_5376.txt': -1, 'cv745_14009.txt': -1, 'cv165_2389.txt': -1, 'cv585_23576.txt': -1, 'cv384_18536.txt': -1, 'cv763_16486.txt': -1, 'cv442_15499.txt': -1, 'cv033_25680.txt': -1, 'cv933_24953.txt': -1, 'cv641_13412.txt': -1, 'cv216_20165.txt': -1, 'cv601_24759.txt': -1, 'cv572_20053.txt': -1, 'cv894_22140.txt': -1, 'cv618_9469.txt': -1, 'cv376_20883.txt': -1, 'cv860_15520.txt': -1, 'cv914_2856.txt': -1, 'cv983_24219.txt': -1, 'cv583_29465.txt': -1, 'cv584_29549.txt': -1, 'cv166_11959.txt': -1, 'cv959_16218.txt': -1, 'cv004_12641.txt': -1, 'cv706_25883.txt': -1, 'cv579_12542.txt': -1, 'cv947_11316.txt': -1, 'cv929_1841.txt': -1, 'cv713_29002.txt': -1, 'cv226_26692.txt': -1, 'cv561_9484.txt': -1, 'cv951_11816.txt': -1, 'cv495_16121.txt': -1, 'cv420_28631.txt': -1, 'cv761_13769.txt': -1, 'cv346_19198.txt': -1, 'cv106_18379.txt': -1, 'cv389_9611.txt': -1, 'cv488_21453.txt': -1, 'cv850_18185.txt': -1, 'cv129_18373.txt': -1, 'cv436_20564.txt': -1, 'cv032_23718.txt': -1, 'cv087_2145.txt': -1, 'cv075_6250.txt': -1, 'cv303_27366.txt': -1, 'cv970_19532.txt': -1, 'cv174_9735.txt': -1, 'cv700_23163.txt': -1, 'cv690_5425.txt': -1, 'cv781_5358.txt': -1, 'cv910_21930.txt': -1, 'cv571_29292.txt': -1, 'cv890_3515.txt': -1, 'cv047_18725.txt': -1, 'cv605_12730.txt': -1, 'cv454_21961.txt': -1, 'cv280_8651.txt': -1, 'cv869_24782.txt': -1, 'cv920_29423.txt': -1, 'cv414_11161.txt': -1, 'cv181_16083.txt': -1, 'cv433_10443.txt': -1, 'cv693_19147.txt': -1, 'cv472_29140.txt': -1, 'cv990_12443.txt': -1, 'cv675_22871.txt': -1, 'cv809_5012.txt': -1, 'cv232_16768.txt': -1, 'cv298_24487.txt': -1, 'cv787_15277.txt': -1, 'cv056_14663.txt': -1, 'cv404_21805.txt': -1, 'cv059_28723.txt': -1, 'cv451_11502.txt': -1, 'cv029_19943.txt': -1, 'cv016_4348.txt': -1, 'cv546_12723.txt': -1, 'cv286_26156.txt': -1, 'cv120_3793.txt': -1, 'cv061_9321.txt': -1, 'cv238_14285.txt': -1, 'cv143_21158.txt': -1, 'cv157_29302.txt': -1, 'cv624_11601.txt': -1, 'cv694_4526.txt': -1, 'cv757_10668.txt': -1, 'cv950_13478.txt': -1, 'cv562_10847.txt': -1, 'cv608_24647.txt': -1, 'cv241_24602.txt': -1, 'cv746_10471.txt': -1, 'cv889_22670.txt': -1, 'cv315_12638.txt': -1, 'cv829_21725.txt': -1, 'cv202_11382.txt': -1, 'cv796_17243.txt': -1, 'cv071_12969.txt': -1, 'cv082_11979.txt': -1, 'cv870_18090.txt': -1, 'cv043_16808.txt': -1, 'cv391_11615.txt': -1, 'cv380_8164.txt': -1, 'cv997_5152.txt': -1, 'cv998_15691.txt': -1, 'cv512_17618.txt': -1, 'cv640_5380.txt': -1, 'cv550_23226.txt': -1, 'cv548_18944.txt': -1, 'cv701_15880.txt': -1, 'cv954_19932.txt': -1, 'cv019_16117.txt': -1, 'cv039_5963.txt': -1, 'cv626_7907.txt': -1, 'cv689_13701.txt': -1, 'cv117_25625.txt': -1, 'cv518_14798.txt': -1, 'cv154_9562.txt': -1, 'cv148_18084.txt': -1, 'cv428_12202.txt': -1, 'cv177_10904.txt': -1, 'cv337_29061.txt': -1, 'cv374_26455.txt': -1, 'cv357_14710.txt': -1, 'cv169_24973.txt': -1, 'cv727_5006.txt': -1, 'cv861_12809.txt': -1, 'cv955_26154.txt': -1, 'cv982_22209.txt': -1, 'cv880_29629.txt': -1, 'cv792_3257.txt': -1, 'cv325_18330.txt': -1, 'cv741_12765.txt': -1, 'cv263_20693.txt': -1, 'cv539_21865.txt': -1, 'cv299_17950.txt': -1, 'cv400_20631.txt': -1, 'cv825_5168.txt': -1, 'cv597_26744.txt': -1, 'cv716_11153.txt': -1, 'cv996_12447.txt': -1, 'cv220_28906.txt': -1, 'cv820_24157.txt': -1, 'cv272_20313.txt': -1, 'cv682_17947.txt': -1, 'cv685_5710.txt': -1, 'cv978_22192.txt': -1, 'cv248_15672.txt': -1, 'cv233_17614.txt': -1, 'cv647_15275.txt': -1, 'cv698_16930.txt': -1, 'cv194_12855.txt': -1, 'cv806_9405.txt': -1, 'cv193_5393.txt': -1, 'cv405_21868.txt': -1, 'cv707_11421.txt': -1, 'cv072_5928.txt': -1, 'cv808_13773.txt': -1, 'cv147_22625.txt': -1, 'cv892_18788.txt': -1, 'cv267_16618.txt': -1, 'cv441_15276.txt': -1, 'cv259_11827.txt': -1, 'cv161_12224.txt': -1, 'cv896_17819.txt': -1, 'cv424_9268.txt': -1, 'cv908_17779.txt': -1, 'cv639_10797.txt': -1, 'cv338_9183.txt': -1, 'cv907_3193.txt': -1, 'cv574_23191.txt': -1, 'cv596_4367.txt': -1, 'cv477_23530.txt': -1, 'cv080_14899.txt': -1, 'cv385_29621.txt': -1, 'cv239_29828.txt': -1, 'cv246_28668.txt': -1, 'cv069_11613.txt': -1, 'cv079_12766.txt': -1, 'cv152_9052.txt': -1, 'cv672_27988.txt': -1, 'cv606_17672.txt': -1, 'cv419_14799.txt': -1, 'cv321_14191.txt': -1, 'cv917_29484.txt': -1, 'cv555_25047.txt': -1, 'cv008_29326.txt': -1, 'cv927_11471.txt': -1, 'cv231_11028.txt': -1, 'cv160_10848.txt': -1, 'cv953_7078.txt': -1, 'cv457_19546.txt': -1, 'cv237_20635.txt': -1, 'cv042_11927.txt': -1, 'cv742_8279.txt': -1, 'cv629_16604.txt': -1, 'cv783_14724.txt': -1, 'cv993_29565.txt': -1, 'cv935_24977.txt': -1, 'cv387_12391.txt': -1, 'cv972_26837.txt': -1, 'cv103_11943.txt': -1, 'cv142_23657.txt': -1, 'cv306_10859.txt': -1, 'cv995_23113.txt': -1, 'cv274_26379.txt': -1, 'cv949_21565.txt': -1, 'cv576_15688.txt': -1, 'cv721_28993.txt': -1, 'cv508_17742.txt': -1, 'cv104_19176.txt': -1, 'cv709_11173.txt': -1, 'cv723_9002.txt': -1, 'cv794_17353.txt': -1, 'cv985_5964.txt': -1, 'cv879_16585.txt': -1, 'cv831_16325.txt': -1, 'cv020_9234.txt': -1, 'cv785_23748.txt': -1, 'cv275_28725.txt': -1, 'cv842_5702.txt': -1, 'cv543_5107.txt': -1, 'cv532_6495.txt': -1, 'cv187_14112.txt': -1, 'cv011_13044.txt': -1, 'cv450_8319.txt': -1, 'cv247_14668.txt': -1, 'cv236_12427.txt': -1, 'cv827_19479.txt': -1, 'cv658_11186.txt': -1, 'cv712_24217.txt': -1, 'cv582_6678.txt': -1, 'cv030_22893.txt': -1, 'cv094_27868.txt': -1, 'cv786_23608.txt': -1, 'cv151_17231.txt': -1, 'cv364_14254.txt': -1, 'cv276_17126.txt': -1, 'cv945_13012.txt': -1, 'cv767_15673.txt': -1, 'cv167_18094.txt': -1, 'cv149_17084.txt': -1, 'cv158_10914.txt': -1, 'cv334_0074.txt': -1, 'cv956_12547.txt': -1, 'cv589_12853.txt': -1, 'cv680_10533.txt': -1, 'cv474_10682.txt': -1, 'cv354_8573.txt': -1, 'cv834_23192.txt': -1, 'cv649_13947.txt': -1, 'cv108_17064.txt': -1, 'cv268_20288.txt': -1, 'cv126_28821.txt': -1, 'cv912_5562.txt': -1, 'cv791_17995.txt': -1, 'cv311_17708.txt': -1, 'cv521_1730.txt': -1, 'cv697_12106.txt': -1, 'cv256_16529.txt': -1, 'cv463_10846.txt': -1, 'cv780_8467.txt': -1, 'cv406_22199.txt': -1, 'cv715_19246.txt': -1, 'cv456_20370.txt': -1, 'cv545_12848.txt': -1, 'cv728_17931.txt': -1, 'cv224_18875.txt': -1, 'cv586_8048.txt': -1, 'cv397_28890.txt': -1, 'cv984_14006.txt': -1, 'cv934_20426.txt': -1, 'cv578_16825.txt': -1, 'cv575_22598.txt': -1, 'cv737_28733.txt': -1, 'cv057_7962.txt': -1, 'cv631_4782.txt': -1, 'cv221_27081.txt': -1, 'cv262_13812.txt': -1, 'cv446_12209.txt': -1, 'cv013_10494.txt': -1, 'cv095_28730.txt': -1, 'cv833_11961.txt': -1, 'cv856_28882.txt': -1, 'cv215_23246.txt': -1, 'cv812_19051.txt': -1, 'cv875_5622.txt': -1, 'cv573_29384.txt': -1, 'cv281_24711.txt': -1, 'cv348_19207.txt': -1, 'cv734_22821.txt': -1, 'cv253_10190.txt': -1, 'cv636_16954.txt': -1, 'cv957_9059.txt': -1, 'cv145_12239.txt': -1, 'cv332_17997.txt': -1, 'cv802_28381.txt': -1, 'cv026_29229.txt': -1, 'cv810_13660.txt': -1, 'cv229_15200.txt': -1, 'cv014_15600.txt': -1, 'cv439_17633.txt': -1, 'cv422_9632.txt': -1, 'cv900_10800.txt': -1, 'cv530_17949.txt': -1, 'cv455_28866.txt': -1, 'cv204_8930.txt': -1, 'cv453_10911.txt': -1, 'cv625_13518.txt': -1, 'cv805_21128.txt': -1, 'cv471_18405.txt': -1, 'cv961_5578.txt': -1, 'cv425_8603.txt': -1, 'cv637_13682.txt': -1, 'cv826_12761.txt': -1, 'cv251_23901.txt': -1, 'cv788_26409.txt': -1, 'cv300_23302.txt': -1, 'cv567_29420.txt': -1, 'cv799_19812.txt': -1, 'cv222_18720.txt': -1, 'cv769_8565.txt': -1, 'cv552_0150.txt': -1, 'cv644_18551.txt': -1, 'cv540_3092.txt': -1, 'cv066_11668.txt': -1, 'cv153_11607.txt': -1, 'cv991_19973.txt': -1, 'cv852_27512.txt': -1, 'cv173_4295.txt': -1, 'cv365_12442.txt': -1, 'cv214_13285.txt': -1, 'cv077_23172.txt': -1, 'cv459_21834.txt': -1, 'cv620_2556.txt': -1, 'cv673_25874.txt': -1, 'cv722_7571.txt': -1, 'cv992_12806.txt': -1, 'cv733_9891.txt': -1, 'cv807_23024.txt': -1, 'cv511_10360.txt': -1, 'cv118_28837.txt': -1, 'cv942_18509.txt': -1, 'cv577_28220.txt': -1, 'cv898_1576.txt': -1, 'cv598_18184.txt': -1, 'cv083_25491.txt': -1, 'cv290_11981.txt': -1, 'cv678_14887.txt': -1, 'cv135_12506.txt': -1, 'cv588_14467.txt': -1, 'cv654_19345.txt': -1, 'cv018_21672.txt': -1, 'cv048_18380.txt': -1, 'cv207_29141.txt': -1, 'cv096_12262.txt': -1, 'cv516_12117.txt': -1, 'cv369_14245.txt': -1, 'cv345_9966.txt': -1, 'cv695_22268.txt': -1, 'cv484_26169.txt': -1, 'cv339_22452.txt': -1, 'cv001_19502.txt': -1, 'cv163_10110.txt': -1, 'cv581_20790.txt': -1, 'cv277_20467.txt': -1, 'cv358_11557.txt': -1, 'cv469_21998.txt': -1, 'cv642_29788.txt': -1, 'cv976_10724.txt': -1, 'cv244_22935.txt': -1, 'cv058_8469.txt': -1, 'cv307_26382.txt': -1, 'cv305_9937.txt': -1, 'cv355_18174.txt': -1, 'cv772_12971.txt': -1, 'cv750_10606.txt': -1, 'cv243_22164.txt': -1, 'cv764_12701.txt': -1, 'cv674_11593.txt': -1, 'cv980_11851.txt': -1, 'cv351_17029.txt': -1, 'cv111_12253.txt': -1, 'cv551_11214.txt': -1, 'cv402_16097.txt': -1, 'cv871_25971.txt': -1, 'cv878_17204.txt': -1, 'cv989_17297.txt': -1, 'cv719_5581.txt': -1, 'cv084_15183.txt': -1, 'cv188_20687.txt': -1, 'cv766_7983.txt': -1, 'cv857_17527.txt': -1, 'cv340_14776.txt': -1, 'cv872_13710.txt': -1, 'cv771_28466.txt': -1, 'cv230_7913.txt': -1, 'cv559_0057.txt': -1, 'cv266_26644.txt': -1, 'cv125_9636.txt': -1, 'cv566_8967.txt': -1, 'cv628_20758.txt': -1, 'cv218_25651.txt': -1, 'cv353_19197.txt': -1, 'cv417_14653.txt': -1, 'cv999_14636.txt': -1, 'cv265_11625.txt': -1, 'cv462_20788.txt': -1, 'cv093_15606.txt': -1, 'cv897_11703.txt': -1, 'cv899_17812.txt': -1, 'cv068_14810.txt': -1, 'cv536_27221.txt': -1, 'cv568_17065.txt': -1, 'cv940_18935.txt': -1, 'cv399_28593.txt': -1, 'cv438_8500.txt': -1, 'cv683_13047.txt': -1, 'cv211_9955.txt': -1, 'cv663_14484.txt': -1, 'cv662_14791.txt': -1, 'cv245_8938.txt': -1, 'cv116_28734.txt': -1, 'cv594_11945.txt': -1, 'cv099_11189.txt': -1, 'cv427_11693.txt': -1, 'cv510_24758.txt': -1, 'cv373_21872.txt': -1, 'cv590_20712.txt': -1, 'cv657_25835.txt': -1, 'cv952_26375.txt': -1, 'cv570_28960.txt': -1, 'cv219_19874.txt': -1, 'cv199_9721.txt': -1, 'cv895_22200.txt': -1, 'cv967_5626.txt': -1, 'cv480_21195.txt': -1, 'cv533_9843.txt': -1, 'cv958_13020.txt': -1, 'cv840_18033.txt': -1, 'cv046_10613.txt': -1, 'cv743_17023.txt': -1, 'cv190_27176.txt': -1, 'cv544_5301.txt': -1, 'cv342_20917.txt': -1, 'cv213_20300.txt': -1, 'cv613_23104.txt': -1, 'cv868_12799.txt': -1, 'cv813_6649.txt': -1, 'cv648_17277.txt': -1, 'cv811_22646.txt': -1, 'cv800_13494.txt': -1, 'cv717_17472.txt': -1, 'cv336_10363.txt': -1, 'cv408_5367.txt': -1, 'cv136_12384.txt': -1, 'cv859_15689.txt': -1, 'cv051_10751.txt': -1, 'cv164_23451.txt': -1, 'cv587_20532.txt': -1, 'cv595_26420.txt': -1, 'cv974_24303.txt': -1, 'cv814_20316.txt': -1, 'cv765_20429.txt': -1, 'cv363_29273.txt': -1, 'cv881_14767.txt': -1, 'cv278_14533.txt': -1, 'cv060_11754.txt': -1, 'cv504_29120.txt': -1, 'cv470_17444.txt': -1, 'cv017_23487.txt': -1, 'cv666_20301.txt': -1, 'cv031_19540.txt': -1, 'cv301_13010.txt': -1, 'cv599_22197.txt': -1, 'cv494_18689.txt': -1, 'cv843_17054.txt': -1, 'cv906_12332.txt': -1, 'cv331_8656.txt': -1, 'cv591_24887.txt': -1, 'cv021_17313.txt': -1, 'cv832_24713.txt': -1, 'cv919_18155.txt': -1, 'cv090_0049.txt': -1, 'cv182_7791.txt': -1, 'cv760_8977.txt': -1, 'cv395_11761.txt': -1, 'cv092_27987.txt': -1, 'cv172_12037.txt': -1, 'cv503_11196.txt': -1, 'cv873_19937.txt': -1, 'cv981_16679.txt': -1, 'cv209_28973.txt': -1, 'cv269_23018.txt': -1, 'cv432_15873.txt': -1, 'cv418_16562.txt': -1, 'cv659_21483.txt': -1, 'cv528_11669.txt': -1, 'cv293_29731.txt': -1, 'cv249_12674.txt': -1, 'cv877_29132.txt': -1, 'cv903_18981.txt': -1, 'cv818_10698.txt': -1, 'cv119_9909.txt': -1, 'cv635_0984.txt': -1, 'cv774_15488.txt': -1, 'cv478_15921.txt': -1, 'cv660_23140.txt': -1, 'cv110_27832.txt': -1, 'cv052_29318.txt': -1, 'cv314_16095.txt': -1, 'cv669_24318.txt': -1, 'cv804_11763.txt': -1, 'cv711_12687.txt': -1, 'cv524_24885.txt': -1, 'cv468_16844.txt': -1, 'cv846_29359.txt': -1, 'cv329_29293.txt': -1, 'cv677_18938.txt': -1, 'cv064_25842.txt': -1, 'cv078_16506.txt': -1, 'cv473_7869.txt': -1, 'cv328_10908.txt': -1, 'cv977_4776.txt': -1, 'cv966_28671.txt': -1, 'cv309_23737.txt': -1, 'cv076_26009.txt': -1, 'cv797_7245.txt': -1, 'cv444_9975.txt': -1, 'cv375_9932.txt': -1, 'cv911_21695.txt': -1, 'cv557_12237.txt': -1, 'cv505_12926.txt': -1, 'cv178_14380.txt': -1, 'cv186_2396.txt': -1, 'cv360_8927.txt': -1, 'cv668_18848.txt': -1, 'cv316_5972.txt': -1, 'cv323_29633.txt': -1, 'cv696_29619.txt': -1, 'cv449_9126.txt': -1, 'cv124_3903.txt': -1, 'cv396_19127.txt': -1, 'cv100_12406.txt': -1, 'cv156_11119.txt': -1, 'cv652_15653.txt': -1, 'cv500_10722.txt': -1, 'cv045_25077.txt': -1, 'cv383_14662.txt': -1, 'cv304_28489.txt': -1, 'cv619_13677.txt': -1, 'cv732_13092.txt': -1, 'cv261_11855.txt': -1, 'cv538_28485.txt': -1, 'cv726_4365.txt': -1, 'cv476_18402.txt': -1, 'cv616_29187.txt': -1, 'cv372_6654.txt': -1, 'cv973_10171.txt': -1, 'cv603_18885.txt': -1, 'cv817_3675.txt': -1, 'cv515_18484.txt': -1, 'cv864_3087.txt': -1, 'cv901_11934.txt': -1, 'cv070_13249.txt': -1, 'cv916_17034.txt': -1, 'cv751_17208.txt': -1, 'cv720_5383.txt': -1, 'cv361_28738.txt': -1, 'cv196_28898.txt': -1, 'cv670_2666.txt': -1, 'cv517_20616.txt': -1, 'cv343_10906.txt': -1, 'cv621_15984.txt': -1, 'cv333_9443.txt': -1, 'cv793_15235.txt': -1, 'cv848_10061.txt': -1, 'cv041_22364.txt': -1, 'cv367_24065.txt': -1, 'cv509_17354.txt': -1, 'cv133_18065.txt': -1, 'cv130_18521.txt': -1, 'cv242_11354.txt': -1, 'cv724_15265.txt': -1, 'cv285_18186.txt': -1, 'cv132_5423.txt': -1, 'cv381_21673.txt': -1, 'cv403_6721.txt': -1, 'cv452_5179.txt': -1, 'cv284_20530.txt': -1, 'cv830_5778.txt': -1, 'cv138_13903.txt': -1, 'cv183_19826.txt': -1, 'cv863_7912.txt': -1, 'cv431_7538.txt': -1, 'cv924_29397.txt': -1, 'cv779_18989.txt': -1, 'cv250_26462.txt': -1, 'cv434_5641.txt': -1, 'cv593_11931.txt': -1, 'cv994_13229.txt': -1, 'cv197_29271.txt': -1, 'cv661_25780.txt': -1, 'cv513_7236.txt': -1, 'cv175_7375.txt': -1, 'cv407_23928.txt': -1, 'cv968_25413.txt': -1, 'cv413_7893.txt': -1, 'cv466_20092.txt': -1, 'cv928_9478.txt': -1, 'cv062_24556.txt': -1, 'cv874_12182.txt': -1, 'cv005_29357.txt': -1, 'cv653_2107.txt': -1, 'cv273_28961.txt': -1, 'cv565_29403.txt': -1, 'cv443_22367.txt': -1, 'cv412_25254.txt': -1, 'cv855_22134.txt': -1, 'cv882_10042.txt': -1, 'cv002_17424.txt': -1, 'cv481_7930.txt': -1, 'cv191_29539.txt': -1, 'cv235_10704.txt': -1, 'cv000_29416.txt': -1, 'cv086_19488.txt': -1, 'cv067_21192.txt': -1, 'cv569_26750.txt': -1, 'cv821_29283.txt': -1, 'cv091_7899.txt': -1, 'cv486_9788.txt': -1, 'cv255_15267.txt': -1, 'cv159_29374.txt': -1, 'cv085_15286.txt': -1, 'cv081_18241.txt': -1, 'cv012_29411.txt': -1, 'cv252_24974.txt': -1}\n"
     ]
    }
   ],
   "source": [
    "# You can use binary encoding for the sentiments , i.e y = 1 for positive sentiments and y = −1 for negative sentiments.\n",
    "def encode_sentiments(folder_path, label):\n",
    "\tencoding = {}\n",
    "\tfor filename in os.listdir(folder_path):\n",
    "\t\tif filename.endswith('.txt'):\n",
    "\t\t\tencoding[filename] = label\n",
    "\treturn encoding\n",
    "\n",
    "pos_encoding = encode_sentiments(POSPATH, 1)\n",
    "neg_encoding = encode_sentiments(NEGPATH, -1)\n",
    "print(pos_encoding)\n",
    "print(neg_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text\n",
    "\n",
    "def process_files_in_folder(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if filename.endswith('.txt'):\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "            cleaned_content = preprocess_text(content)\n",
    "            with open(file_path, 'w', encoding='utf-8') as file:\n",
    "                file.write(cleaned_content)\n",
    "            # print(f'Processed file: {filename}')\n",
    "\n",
    "process_files_in_folder(POSPATH)\n",
    "process_files_in_folder(NEGPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = glob.glob(\"../data/pos/*.txt\")\n",
    "neg = glob.glob(\"../data/neg/*.txt\")\n",
    "\n",
    "total_sentiments = pos + neg\n",
    "l = [pd.read_csv(filename) for filename in total_sentiments]\n",
    "assert len(total_sentiments) == len(pos) + len(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_train_files = pd.DataFrame(pos)[0].sort_values()[0:700]\n",
    "pos_test_files = pd.DataFrame(pos)[0].sort_values()[700:]\n",
    "neg_train_files = pd.DataFrame(neg)[0].sort_values()[0:700]\n",
    "neg_test_files = pd.DataFrame(neg)[0].sort_values()[700:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29     ../data/pos/cv000_29590.txt\n",
       "621    ../data/pos/cv001_18431.txt\n",
       "390    ../data/pos/cv002_15918.txt\n",
       "396    ../data/pos/cv003_11664.txt\n",
       "708    ../data/pos/cv004_11636.txt\n",
       "                  ...             \n",
       "10     ../data/pos/cv695_21108.txt\n",
       "835    ../data/pos/cv696_29740.txt\n",
       "382    ../data/pos/cv697_11162.txt\n",
       "124    ../data/pos/cv698_15253.txt\n",
       "963     ../data/pos/cv699_7223.txt\n",
       "Name: 0, Length: 700, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_train_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique words: 46825\n"
     ]
    }
   ],
   "source": [
    "unique_words = set()\n",
    "\n",
    "for review in total_sentiments:\n",
    "\t# with open('../data/neg/cv000_29416.txt') as file:\n",
    "\twith open(review) as file:\n",
    "\t\ttext = file.read()\n",
    "\t\twords_in_text = word_tokenize(text)\n",
    "\t\tfor word in words_in_text:\n",
    "\t\t\tunique_words.add(word)\n",
    "\n",
    "print(f\"number of unique words: {len(unique_words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Word Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv839_21467.txt</td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv034_29647.txt</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv908_16009.txt</td>\n",
       "      <td>1589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cv748_12786.txt</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cv253_10077.txt</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>cv159_29374.txt</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>cv085_15286.txt</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>cv081_18241.txt</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>cv012_29411.txt</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>cv252_24974.txt</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Filename  Word Count\n",
       "0     cv839_21467.txt         790\n",
       "1     cv034_29647.txt         616\n",
       "2     cv908_16009.txt        1589\n",
       "3     cv748_12786.txt         423\n",
       "4     cv253_10077.txt         278\n",
       "...               ...         ...\n",
       "1995  cv159_29374.txt         302\n",
       "1996  cv085_15286.txt         528\n",
       "1997  cv081_18241.txt         270\n",
       "1998  cv012_29411.txt         451\n",
       "1999  cv252_24974.txt         698\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_lengths_data = []\n",
    "\n",
    "for review in total_sentiments:\n",
    "\t# with open('../data/neg/cv000_29416.txt') as file:\n",
    "\twith open(review) as file:\n",
    "\t\ttext = file.read()\n",
    "\t\ttokens = word_tokenize(text)\n",
    "\t\tfilename = review.split(\"/\")[-1]\n",
    "\t\tword_count = len(tokens)\n",
    "\t\treview_lengths_data.append([filename, word_count])\n",
    "\n",
    "review_lengths_df = pd.DataFrame(review_lengths_data, columns=[\"Filename\", \"Word Count\"])\n",
    "review_lengths_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Review Length: 644.473\n",
      "Review Length Standard Deviation: 285.09774048879467\n"
     ]
    }
   ],
   "source": [
    "mean_word_count = review_lengths_df[\"Word Count\"].mean()\n",
    "print(f\"Average Review Length: {mean_word_count}\")\n",
    "\n",
    "std_word_count = review_lengths_df[\"Word Count\"].std()\n",
    "print(f\"Review Length Standard Deviation: {std_word_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(review_lengths_df[\"Word Count\"])\n",
    "plt.title('Review Lengths Histogram')\n",
    "plt.xlabel('Word Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (vii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Word Ranks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv000_29416.txt</td>\n",
       "      <td>[98, 79, 1078, 3641, 129, 5, 2, 1966, 782, 364...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv001_19502.txt</td>\n",
       "      <td>[1, 674, 6289, 1047, 27, 455, 1526, 8, 14977, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv002_17424.txt</td>\n",
       "      <td>[9, 6, 101, 39, 110, 8, 86, 2, 7661, 27, 712, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cv003_12683.txt</td>\n",
       "      <td>[1914, 12, 8125, 6, 2750, 4627, 80, 7260, 2734...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cv004_12641.txt</td>\n",
       "      <td>[1968, 2, 3480, 6599, 116, 17381, 20942, 2915,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>cv995_21821.txt</td>\n",
       "      <td>[4094, 48, 2, 27, 23, 267, 2, 27, 64, 22, 176,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>cv996_11592.txt</td>\n",
       "      <td>[882, 3377, 64, 22, 2, 3840, 275, 16, 122, 25,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>cv997_5046.txt</td>\n",
       "      <td>[46800, 1196, 2476, 4252, 1861, 3, 2529, 46801...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>cv998_14111.txt</td>\n",
       "      <td>[1004, 3841, 369, 1406, 15, 19, 148, 391, 1025...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>cv999_13106.txt</td>\n",
       "      <td>[1028, 46817, 6285, 6, 1, 402, 354, 12, 772, 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Filename                                         Word Ranks\n",
       "0     cv000_29416.txt  [98, 79, 1078, 3641, 129, 5, 2, 1966, 782, 364...\n",
       "1     cv001_19502.txt  [1, 674, 6289, 1047, 27, 455, 1526, 8, 14977, ...\n",
       "2     cv002_17424.txt  [9, 6, 101, 39, 110, 8, 86, 2, 7661, 27, 712, ...\n",
       "3     cv003_12683.txt  [1914, 12, 8125, 6, 2750, 4627, 80, 7260, 2734...\n",
       "4     cv004_12641.txt  [1968, 2, 3480, 6599, 116, 17381, 20942, 2915,...\n",
       "...               ...                                                ...\n",
       "1995  cv995_21821.txt  [4094, 48, 2, 27, 23, 267, 2, 27, 64, 22, 176,...\n",
       "1996  cv996_11592.txt  [882, 3377, 64, 22, 2, 3840, 275, 16, 122, 25,...\n",
       "1997   cv997_5046.txt  [46800, 1196, 2476, 4252, 1861, 3, 2529, 46801...\n",
       "1998  cv998_14111.txt  [1004, 3841, 369, 1406, 15, 19, 148, 391, 1025...\n",
       "1999  cv999_13106.txt  [1028, 46817, 6285, 6, 1, 402, 354, 12, 772, 4...\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46825</th>\n",
       "      <td>tangerine</td>\n",
       "      <td>46826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46826</th>\n",
       "      <td>timbre</td>\n",
       "      <td>46827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46827</th>\n",
       "      <td>powaqqatsi</td>\n",
       "      <td>46828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46828</th>\n",
       "      <td>keyboardist</td>\n",
       "      <td>46829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46829</th>\n",
       "      <td>capitalized</td>\n",
       "      <td>46830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46830 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word   Rank\n",
       "0              the      1\n",
       "1                a      2\n",
       "2              and      3\n",
       "3               of      4\n",
       "4               to      5\n",
       "...            ...    ...\n",
       "46825    tangerine  46826\n",
       "46826       timbre  46827\n",
       "46827   powaqqatsi  46828\n",
       "46828  keyboardist  46829\n",
       "46829  capitalized  46830\n",
       "\n",
       "[46830 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "texts = []\n",
    "total_sentiments = sorted(total_sentiments)\n",
    "for review in total_sentiments:\n",
    "    with open(review, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        texts.append(text)\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "rank_data = []\n",
    "for review, sequence in zip(total_sentiments, sequences):\n",
    "    filename = review.split(\"/\")[-1]\n",
    "    rank_data.append([filename, sequence])\n",
    "\n",
    "sequences_df = pd.DataFrame(rank_data, columns=['Filename', 'Word Ranks'])\n",
    "word_index_df = pd.DataFrame(list(word_index.items()), columns=['Word', 'Rank']).sort_values(by='Rank')\n",
    "\n",
    "display(sequences_df)\n",
    "display(word_index_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (viii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Word Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>cv506_17521.txt</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <td>cv779_18989.txt</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>cv857_17527.txt</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>cv280_8267.txt</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>cv435_24355.txt</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>cv146_18458.txt</td>\n",
       "      <td>1844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>cv638_2953.txt</td>\n",
       "      <td>1879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>cv765_19037.txt</td>\n",
       "      <td>2190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>cv597_26360.txt</td>\n",
       "      <td>2264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>cv552_10016.txt</td>\n",
       "      <td>2363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Filename  Word Count\n",
       "1051  cv506_17521.txt          16\n",
       "1959  cv779_18989.txt          65\n",
       "1755  cv857_17527.txt         103\n",
       "574    cv280_8267.txt         112\n",
       "1091  cv435_24355.txt         119\n",
       "...               ...         ...\n",
       "268   cv146_18458.txt        1844\n",
       "651    cv638_2953.txt        1879\n",
       "650   cv765_19037.txt        2190\n",
       "725   cv597_26360.txt        2264\n",
       "917   cv552_10016.txt        2363\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_review_lengths_df = review_lengths_df.sort_values(by=\"Word Count\")\n",
    "sorted_review_lengths_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "737"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = sorted_review_lengths_df[\"Word Count\"].quantile(0.70)\n",
    "L = int(L)\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Word Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>cv486_9788.txt</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>cv884_13632.txt</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>cv604_2230.txt</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>cv636_16954.txt</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>cv963_7208.txt</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>cv146_18458.txt</td>\n",
       "      <td>1844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>cv638_2953.txt</td>\n",
       "      <td>1879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>cv765_19037.txt</td>\n",
       "      <td>2190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>cv597_26360.txt</td>\n",
       "      <td>2264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>cv552_10016.txt</td>\n",
       "      <td>2363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>597 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Filename  Word Count\n",
       "1993   cv486_9788.txt         738\n",
       "208   cv884_13632.txt         738\n",
       "923    cv604_2230.txt         738\n",
       "1655  cv636_16954.txt         739\n",
       "1220   cv963_7208.txt         739\n",
       "...               ...         ...\n",
       "268   cv146_18458.txt        1844\n",
       "651    cv638_2953.txt        1879\n",
       "650   cv765_19037.txt        2190\n",
       "725   cv597_26360.txt        2264\n",
       "917   cv552_10016.txt        2363\n",
       "\n",
       "[597 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_review_lengths_df[sorted_review_lengths_df[\"Word Count\"] > 737]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Padded Word Ranks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv000_29416.txt</td>\n",
       "      <td>[98, 79, 1078, 3641, 129, 5, 2, 1966, 782, 364...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv001_19502.txt</td>\n",
       "      <td>[1, 674, 6289, 1047, 27, 455, 1526, 8, 14977, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv002_17424.txt</td>\n",
       "      <td>[9, 6, 101, 39, 110, 8, 86, 2, 7661, 27, 712, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cv003_12683.txt</td>\n",
       "      <td>[1914, 12, 8125, 6, 2750, 4627, 80, 7260, 2734...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cv004_12641.txt</td>\n",
       "      <td>[1968, 2, 3480, 6599, 116, 17381, 20942, 2915,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>cv995_21821.txt</td>\n",
       "      <td>[4094, 48, 2, 27, 23, 267, 2, 27, 64, 22, 176,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>cv996_11592.txt</td>\n",
       "      <td>[882, 3377, 64, 22, 2, 3840, 275, 16, 122, 25,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>cv997_5046.txt</td>\n",
       "      <td>[46800, 1196, 2476, 4252, 1861, 3, 2529, 46801...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>cv998_14111.txt</td>\n",
       "      <td>[1004, 3841, 369, 1406, 15, 19, 148, 391, 1025...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>cv999_13106.txt</td>\n",
       "      <td>[1028, 46817, 6285, 6, 1, 402, 354, 12, 772, 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Filename                                  Padded Word Ranks\n",
       "0     cv000_29416.txt  [98, 79, 1078, 3641, 129, 5, 2, 1966, 782, 364...\n",
       "1     cv001_19502.txt  [1, 674, 6289, 1047, 27, 455, 1526, 8, 14977, ...\n",
       "2     cv002_17424.txt  [9, 6, 101, 39, 110, 8, 86, 2, 7661, 27, 712, ...\n",
       "3     cv003_12683.txt  [1914, 12, 8125, 6, 2750, 4627, 80, 7260, 2734...\n",
       "4     cv004_12641.txt  [1968, 2, 3480, 6599, 116, 17381, 20942, 2915,...\n",
       "...               ...                                                ...\n",
       "1995  cv995_21821.txt  [4094, 48, 2, 27, 23, 267, 2, 27, 64, 22, 176,...\n",
       "1996  cv996_11592.txt  [882, 3377, 64, 22, 2, 3840, 275, 16, 122, 25,...\n",
       "1997   cv997_5046.txt  [46800, 1196, 2476, 4252, 1861, 3, 2529, 46801...\n",
       "1998  cv998_14111.txt  [1004, 3841, 369, 1406, 15, 19, 148, 391, 1025...\n",
       "1999  cv999_13106.txt  [1028, 46817, 6285, 6, 1, 402, 354, 12, 772, 4...\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0       [98, 79, 1078, 3641, 129, 5, 2, 1966, 782, 364...\n",
       "1       [1, 674, 6289, 1047, 27, 455, 1526, 8, 14977, ...\n",
       "2       [9, 6, 101, 39, 110, 8, 86, 2, 7661, 27, 712, ...\n",
       "3       [1914, 12, 8125, 6, 2750, 4627, 80, 7260, 2734...\n",
       "4       [1968, 2, 3480, 6599, 116, 17381, 20942, 2915,...\n",
       "                              ...                        \n",
       "1995    [4094, 48, 2, 27, 23, 267, 2, 27, 64, 22, 176,...\n",
       "1996    [882, 3377, 64, 22, 2, 3840, 275, 16, 122, 25,...\n",
       "1997    [46800, 1196, 2476, 4252, 1861, 3, 2529, 46801...\n",
       "1998    [1004, 3841, 369, 1406, 15, 19, 148, 391, 1025...\n",
       "1999    [1028, 46817, 6285, 6, 1, 402, 354, 12, 772, 4...\n",
       "Name: Padded Word Ranks, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences = pad_sequences(sequences, maxlen=L, padding='post', truncating='post')\n",
    "\n",
    "padded_rank_data = []\n",
    "for review, sequence in zip(total_sentiments, padded_sequences):\n",
    "    filename = review.split(\"/\")[-1]\n",
    "    padded_rank_data.append([filename, sequence])\n",
    "\n",
    "padded_sequences_df = pd.DataFrame(padded_rank_data, columns=['Filename', 'Padded Word Ranks'])\n",
    "\n",
    "display(padded_sequences_df)\n",
    "padded_sequences_df['Padded Word Ranks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(737,)\n"
     ]
    }
   ],
   "source": [
    "print(padded_sequences_df['Padded Word Ranks'][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dsci552/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "top_words = 5000\n",
    "embedding_dim = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=top_words, output_dim=embedding_dim, input_length=L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_out_of_range(arr):\n",
    "    return np.where((arr >= 1) & (arr <= 4999), arr, 0)\n",
    "\n",
    "padded_sequences_df['Padded Word Ranks'] = padded_sequences_df['Padded Word Ranks'].apply(replace_out_of_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Padded Word Ranks</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv000_29416.txt</td>\n",
       "      <td>[98, 79, 1078, 3641, 129, 5, 2, 1966, 782, 364...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv001_19502.txt</td>\n",
       "      <td>[1, 674, 0, 1047, 27, 455, 1526, 8, 0, 2912, 2...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv002_17424.txt</td>\n",
       "      <td>[9, 6, 101, 39, 110, 8, 86, 2, 0, 27, 712, 0, ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cv003_12683.txt</td>\n",
       "      <td>[1914, 12, 0, 6, 2750, 4627, 80, 0, 0, 505, 5,...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cv004_12641.txt</td>\n",
       "      <td>[1968, 2, 3480, 0, 116, 0, 0, 2915, 2, 411, 29...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>cv995_21821.txt</td>\n",
       "      <td>[4094, 48, 2, 27, 23, 267, 2, 27, 64, 22, 176,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>cv996_11592.txt</td>\n",
       "      <td>[882, 3377, 64, 22, 2, 3840, 275, 16, 122, 25,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>cv997_5046.txt</td>\n",
       "      <td>[0, 1196, 2476, 4252, 1861, 3, 2529, 0, 1, 344...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>cv998_14111.txt</td>\n",
       "      <td>[1004, 3841, 369, 1406, 15, 19, 148, 391, 1025...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>cv999_13106.txt</td>\n",
       "      <td>[1028, 0, 0, 6, 1, 402, 354, 12, 772, 4594, 75...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Filename                                  Padded Word Ranks  \\\n",
       "0     cv000_29416.txt  [98, 79, 1078, 3641, 129, 5, 2, 1966, 782, 364...   \n",
       "1     cv001_19502.txt  [1, 674, 0, 1047, 27, 455, 1526, 8, 0, 2912, 2...   \n",
       "2     cv002_17424.txt  [9, 6, 101, 39, 110, 8, 86, 2, 0, 27, 712, 0, ...   \n",
       "3     cv003_12683.txt  [1914, 12, 0, 6, 2750, 4627, 80, 0, 0, 505, 5,...   \n",
       "4     cv004_12641.txt  [1968, 2, 3480, 0, 116, 0, 0, 2915, 2, 411, 29...   \n",
       "...               ...                                                ...   \n",
       "1995  cv995_21821.txt  [4094, 48, 2, 27, 23, 267, 2, 27, 64, 22, 176,...   \n",
       "1996  cv996_11592.txt  [882, 3377, 64, 22, 2, 3840, 275, 16, 122, 25,...   \n",
       "1997   cv997_5046.txt  [0, 1196, 2476, 4252, 1861, 3, 2529, 0, 1, 344...   \n",
       "1998  cv998_14111.txt  [1004, 3841, 369, 1406, 15, 19, 148, 391, 1025...   \n",
       "1999  cv999_13106.txt  [1028, 0, 0, 6, 1, 402, 354, 12, 772, 4594, 75...   \n",
       "\n",
       "      Sentiment  \n",
       "0            -1  \n",
       "1            -1  \n",
       "2            -1  \n",
       "3            -1  \n",
       "4            -1  \n",
       "...         ...  \n",
       "1995          1  \n",
       "1996          1  \n",
       "1997          1  \n",
       "1998          1  \n",
       "1999          1  \n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments = [-1] * 1000 + [1] * 1000\n",
    "padded_sequences_df['Sentiment'] = sentiments\n",
    "padded_sequences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Padded Word Ranks</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv000_29416.txt</td>\n",
       "      <td>[98, 79, 1078, 3641, 129, 5, 2, 1966, 782, 364...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv001_19502.txt</td>\n",
       "      <td>[1, 674, 0, 1047, 27, 455, 1526, 8, 0, 2912, 2...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv002_17424.txt</td>\n",
       "      <td>[9, 6, 101, 39, 110, 8, 86, 2, 0, 27, 712, 0, ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cv003_12683.txt</td>\n",
       "      <td>[1914, 12, 0, 6, 2750, 4627, 80, 0, 0, 505, 5,...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cv004_12641.txt</td>\n",
       "      <td>[1968, 2, 3480, 0, 116, 0, 0, 2915, 2, 411, 29...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>cv695_21108.txt</td>\n",
       "      <td>[28, 69, 32, 360, 772, 1351, 88, 474, 43, 18, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>cv696_29740.txt</td>\n",
       "      <td>[2549, 14, 6, 2, 0, 175, 30, 2, 1314, 0, 4982,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>cv697_11162.txt</td>\n",
       "      <td>[124, 2860, 15, 14, 182, 44, 31, 881, 21, 0, 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>cv698_15253.txt</td>\n",
       "      <td>[2, 3395, 0, 6, 1, 0, 4, 2, 2632, 10, 2, 2334,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>cv699_7223.txt</td>\n",
       "      <td>[78, 147, 100, 69, 22, 4726, 4, 0, 0, 157, 854...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Filename                                  Padded Word Ranks  \\\n",
       "0     cv000_29416.txt  [98, 79, 1078, 3641, 129, 5, 2, 1966, 782, 364...   \n",
       "1     cv001_19502.txt  [1, 674, 0, 1047, 27, 455, 1526, 8, 0, 2912, 2...   \n",
       "2     cv002_17424.txt  [9, 6, 101, 39, 110, 8, 86, 2, 0, 27, 712, 0, ...   \n",
       "3     cv003_12683.txt  [1914, 12, 0, 6, 2750, 4627, 80, 0, 0, 505, 5,...   \n",
       "4     cv004_12641.txt  [1968, 2, 3480, 0, 116, 0, 0, 2915, 2, 411, 29...   \n",
       "...               ...                                                ...   \n",
       "1395  cv695_21108.txt  [28, 69, 32, 360, 772, 1351, 88, 474, 43, 18, ...   \n",
       "1396  cv696_29740.txt  [2549, 14, 6, 2, 0, 175, 30, 2, 1314, 0, 4982,...   \n",
       "1397  cv697_11162.txt  [124, 2860, 15, 14, 182, 44, 31, 881, 21, 0, 1...   \n",
       "1398  cv698_15253.txt  [2, 3395, 0, 6, 1, 0, 4, 2, 2632, 10, 2, 2334,...   \n",
       "1399   cv699_7223.txt  [78, 147, 100, 69, 22, 4726, 4, 0, 0, 157, 854...   \n",
       "\n",
       "      Sentiment  \n",
       "0            -1  \n",
       "1            -1  \n",
       "2            -1  \n",
       "3            -1  \n",
       "4            -1  \n",
       "...         ...  \n",
       "1395          1  \n",
       "1396          1  \n",
       "1397          1  \n",
       "1398          1  \n",
       "1399          1  \n",
       "\n",
       "[1400 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Padded Word Ranks</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv700_23163.txt</td>\n",
       "      <td>[1, 1821, 6, 2, 0, 1429, 15, 8, 18, 64, 57, 19...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv701_15880.txt</td>\n",
       "      <td>[1, 62, 2439, 1434, 4, 23, 2, 0, 46, 149, 4618...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv702_12371.txt</td>\n",
       "      <td>[7, 1, 659, 631, 24, 0, 94, 27, 381, 1781, 297...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cv703_17948.txt</td>\n",
       "      <td>[110, 394, 60, 20, 0, 1, 0, 4, 67, 362, 19, 20...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cv704_17622.txt</td>\n",
       "      <td>[81, 127, 1579, 161, 18, 4611, 8, 1945, 2550, ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>cv995_21821.txt</td>\n",
       "      <td>[4094, 48, 2, 27, 23, 267, 2, 27, 64, 22, 176,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>cv996_11592.txt</td>\n",
       "      <td>[882, 3377, 64, 22, 2, 3840, 275, 16, 122, 25,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>cv997_5046.txt</td>\n",
       "      <td>[0, 1196, 2476, 4252, 1861, 3, 2529, 0, 1, 344...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>cv998_14111.txt</td>\n",
       "      <td>[1004, 3841, 369, 1406, 15, 19, 148, 391, 1025...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>cv999_13106.txt</td>\n",
       "      <td>[1028, 0, 0, 6, 1, 402, 354, 12, 772, 4594, 75...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Filename                                  Padded Word Ranks  \\\n",
       "0    cv700_23163.txt  [1, 1821, 6, 2, 0, 1429, 15, 8, 18, 64, 57, 19...   \n",
       "1    cv701_15880.txt  [1, 62, 2439, 1434, 4, 23, 2, 0, 46, 149, 4618...   \n",
       "2    cv702_12371.txt  [7, 1, 659, 631, 24, 0, 94, 27, 381, 1781, 297...   \n",
       "3    cv703_17948.txt  [110, 394, 60, 20, 0, 1, 0, 4, 67, 362, 19, 20...   \n",
       "4    cv704_17622.txt  [81, 127, 1579, 161, 18, 4611, 8, 1945, 2550, ...   \n",
       "..               ...                                                ...   \n",
       "595  cv995_21821.txt  [4094, 48, 2, 27, 23, 267, 2, 27, 64, 22, 176,...   \n",
       "596  cv996_11592.txt  [882, 3377, 64, 22, 2, 3840, 275, 16, 122, 25,...   \n",
       "597   cv997_5046.txt  [0, 1196, 2476, 4252, 1861, 3, 2529, 0, 1, 344...   \n",
       "598  cv998_14111.txt  [1004, 3841, 369, 1406, 15, 19, 148, 391, 1025...   \n",
       "599  cv999_13106.txt  [1028, 0, 0, 6, 1, 402, 354, 12, 772, 4594, 75...   \n",
       "\n",
       "     Sentiment  \n",
       "0           -1  \n",
       "1           -1  \n",
       "2           -1  \n",
       "3           -1  \n",
       "4           -1  \n",
       "..         ...  \n",
       "595          1  \n",
       "596          1  \n",
       "597          1  \n",
       "598          1  \n",
       "599          1  \n",
       "\n",
       "[600 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0      -1\n",
       "1      -1\n",
       "2      -1\n",
       "3      -1\n",
       "4      -1\n",
       "       ..\n",
       "1395    1\n",
       "1396    1\n",
       "1397    1\n",
       "1398    1\n",
       "1399    1\n",
       "Name: Sentiment, Length: 1400, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0     -1\n",
       "1     -1\n",
       "2     -1\n",
       "3     -1\n",
       "4     -1\n",
       "      ..\n",
       "595    1\n",
       "596    1\n",
       "597    1\n",
       "598    1\n",
       "599    1\n",
       "Name: Sentiment, Length: 600, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "neg_train_padded_sequences_df = padded_sequences_df[:700]\n",
    "neg_test_padded_sequences_df = padded_sequences_df[700:1000]\n",
    "pos_train_padded_sequences_df = padded_sequences_df[1000:1700]\n",
    "pos_test_padded_sequences_df = padded_sequences_df[1700:]\n",
    "train_labels = pd.concat([padded_sequences_df['Sentiment'][:700], padded_sequences_df['Sentiment'][1000:1700]], ignore_index=True)\n",
    "test_labels = pd.concat([padded_sequences_df['Sentiment'][700:1000], padded_sequences_df['Sentiment'][1700:]], ignore_index=True)\n",
    "\n",
    "train_padded_sequences_df = pd.concat([neg_train_padded_sequences_df, pos_train_padded_sequences_df], ignore_index=True)\n",
    "test_padded_sequences_df = pd.concat([neg_test_padded_sequences_df, pos_test_padded_sequences_df], ignore_index=True)\n",
    "display(train_padded_sequences_df)\n",
    "display(test_padded_sequences_df)\n",
    "display(train_labels)\n",
    "display(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_tokens_matrix:\n",
      "(1400, 737)\n",
      "[[  98   79 1078 ...    0    0    0]\n",
      " [   1  674    0 ...    0    0    0]\n",
      " [   9    6  101 ...    0    0    0]\n",
      " ...\n",
      " [ 124 2860   15 ...    0    0    0]\n",
      " [   2 3395    0 ...   85    4    0]\n",
      " [  78  147  100 ...    0    0    0]]\n",
      "\n",
      "test_tokens_matrix:\n",
      "(600, 737)\n",
      "[[   1 1821    6 ...    0    0    0]\n",
      " [   1   62 2439 ...    0    0    0]\n",
      " [   7    1  659 ...    0    0    0]\n",
      " ...\n",
      " [   0 1196 2476 ...    6  108 3216]\n",
      " [1004 3841  369 ...    0    0    0]\n",
      " [1028    0    0 ...  227   26 1719]]\n",
      "train labels:\n",
      "(1400,)\n",
      "[-1 -1 -1 ...  1  1  1]\n",
      "test labels\n",
      "(600,)\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "train_tokens_matrix = train_padded_sequences_df['Padded Word Ranks'].to_numpy()\n",
    "test_tokens_matrix = test_padded_sequences_df['Padded Word Ranks'].to_numpy()\n",
    "train_tokens_matrix = np.array([np.array(lst) for lst in train_tokens_matrix])\n",
    "test_tokens_matrix = np.array([np.array(lst) for lst in test_tokens_matrix])\n",
    "train_labels = train_labels.to_numpy()\n",
    "test_labels = test_labels.to_numpy()\n",
    "\n",
    "print(f\"train_tokens_matrix:\\n{train_tokens_matrix.shape}\\n{train_tokens_matrix}\")\n",
    "print()\n",
    "print(f\"test_tokens_matrix:\\n{test_tokens_matrix.shape}\\n{test_tokens_matrix}\")\n",
    "print(\"train labels:\")\n",
    "print(train_labels.shape)\n",
    "print(train_labels)\n",
    "print(\"test labels\")\n",
    "print(test_labels.shape)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  98,   79, 1078, ...,    0,    0,    0],\n",
       "       [   1,  674,    0, ...,    0,    0,    0],\n",
       "       [   9,    6,  101, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 124, 2860,   15, ...,    0,    0,    0],\n",
       "       [   2, 3395,    0, ...,   85,    4,    0],\n",
       "       [  78,  147,  100, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 737)\n",
      "[[  98   79 1078 ...    0    0    0]\n",
      " [   1  674    0 ...    0    0    0]\n",
      " [   9    6  101 ...    0    0    0]\n",
      " ...\n",
      " [   0 1196 2476 ...    6  108 3216]\n",
      " [1004 3841  369 ...    0    0    0]\n",
      " [1028    0    0 ...  227   26 1719]]\n"
     ]
    }
   ],
   "source": [
    "tokens_matrix = np.vstack(padded_sequences_df['Padded Word Ranks'].to_numpy())\n",
    "print(tokens_matrix.shape)\n",
    "print(tokens_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  98,   79, 1078, ...,    0,    0,    0],\n",
       "       [   1,  674,    0, ...,    0,    0,    0],\n",
       "       [   9,    6,  101, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 124, 2860,   15, ...,    0,    0,    0],\n",
       "       [   2, 3395,    0, ...,   85,    4,    0],\n",
       "       [  78,  147,  100, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step \n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step\n",
      "(1400, 737, 32)\n",
      "(600, 737, 32)\n",
      "[[[ 0.03925676  0.03304542  0.04172217 ... -0.03614228 -0.04543976\n",
      "   -0.01497326]\n",
      "  [ 0.02836312 -0.04374274  0.02616371 ...  0.04891003 -0.02431585\n",
      "    0.04505942]\n",
      "  [-0.00052674  0.01896429  0.01779901 ...  0.02761943 -0.04287001\n",
      "   -0.0261164 ]\n",
      "  ...\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]]\n",
      "\n",
      " [[-0.04987419  0.03953192 -0.03945085 ... -0.04462079  0.0196293\n",
      "    0.04866723]\n",
      "  [-0.03372373  0.02600712  0.01134744 ...  0.00061792 -0.03395934\n",
      "   -0.03049546]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  ...\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]]\n",
      "\n",
      " [[-0.04763654  0.01742664 -0.02228661 ... -0.02611135  0.04441825\n",
      "    0.00218337]\n",
      "  [ 0.00125593  0.04882723 -0.04872293 ...  0.03247661  0.03251083\n",
      "   -0.02441573]\n",
      "  [ 0.03866008 -0.04943422  0.0226743  ... -0.00808561  0.02278126\n",
      "    0.04797177]\n",
      "  ...\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.00263736  0.02807606 -0.04577314 ... -0.02503725  0.01564585\n",
      "   -0.00816629]\n",
      "  [ 0.03392582  0.0291529  -0.04870615 ...  0.04587454  0.01674446\n",
      "   -0.03153674]\n",
      "  [ 0.04697477 -0.02116441  0.01639107 ... -0.02738471 -0.03387912\n",
      "   -0.04242001]\n",
      "  ...\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]]\n",
      "\n",
      " [[ 0.04790515 -0.00057345  0.01550138 ... -0.01486102  0.00396108\n",
      "   -0.0157593 ]\n",
      "  [ 0.04836186  0.01745317 -0.01480393 ...  0.04382977 -0.03712498\n",
      "    0.00981783]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  ...\n",
      "  [-0.02798229  0.00941777  0.02548512 ...  0.02566693 -0.04398887\n",
      "   -0.02831669]\n",
      "  [ 0.02917198 -0.0458445   0.02758909 ... -0.01149274 -0.01344179\n",
      "    0.0348452 ]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]]\n",
      "\n",
      " [[ 0.02195717  0.03610816 -0.00108435 ...  0.03117294 -0.04469118\n",
      "    0.00300471]\n",
      "  [ 0.01445803  0.04651947  0.02705927 ... -0.0370133  -0.04237745\n",
      "    0.03687931]\n",
      "  [ 0.03445754  0.03424693 -0.02312372 ... -0.03148516  0.04499068\n",
      "   -0.04281687]\n",
      "  ...\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]]]\n",
      "[[[-0.04987419  0.03953192 -0.03945085 ... -0.04462079  0.0196293\n",
      "    0.04866723]\n",
      "  [-0.02363789  0.03046736 -0.02738943 ... -0.04034085  0.021911\n",
      "    0.00875844]\n",
      "  [ 0.00125593  0.04882723 -0.04872293 ...  0.03247661  0.03251083\n",
      "   -0.02441573]\n",
      "  ...\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]]\n",
      "\n",
      " [[-0.04987419  0.03953192 -0.03945085 ... -0.04462079  0.0196293\n",
      "    0.04866723]\n",
      "  [ 0.04557505 -0.02686424  0.026537   ...  0.03222339 -0.03663775\n",
      "    0.02208925]\n",
      "  [ 0.0010295  -0.0343604  -0.04055691 ... -0.04990146 -0.02288575\n",
      "    0.04051865]\n",
      "  ...\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]]\n",
      "\n",
      " [[-0.01734027 -0.00104775 -0.03079507 ... -0.02925392 -0.01440639\n",
      "   -0.04730273]\n",
      "  [-0.04987419  0.03953192 -0.03945085 ... -0.04462079  0.0196293\n",
      "    0.04866723]\n",
      "  [-0.04934629  0.02721859 -0.02209462 ...  0.01504466  0.0394051\n",
      "   -0.00125128]\n",
      "  ...\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [ 0.03785595 -0.00170738 -0.04658076 ... -0.01559705  0.02645702\n",
      "   -0.01576991]\n",
      "  [ 0.00561095  0.03006662  0.00558661 ...  0.02182387 -0.03899449\n",
      "   -0.04203566]\n",
      "  ...\n",
      "  [ 0.00125593  0.04882723 -0.04872293 ...  0.03247661  0.03251083\n",
      "   -0.02441573]\n",
      "  [-0.04608832 -0.02723926 -0.03123413 ...  0.00839882  0.03151158\n",
      "   -0.0474172 ]\n",
      "  [-0.0280298   0.03197855  0.02746044 ...  0.03293723 -0.03853252\n",
      "    0.03860709]]\n",
      "\n",
      " [[-0.04278513  0.02390606  0.00973767 ... -0.02941272  0.00424205\n",
      "    0.01911007]\n",
      "  [ 0.04597196  0.02580262 -0.03122749 ... -0.02895995 -0.0229155\n",
      "    0.03037581]\n",
      "  [ 0.04909427  0.03035397 -0.0252364  ... -0.03577337  0.02589289\n",
      "   -0.00284795]\n",
      "  ...\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]]\n",
      "\n",
      " [[ 0.0074226  -0.02335132  0.03274801 ...  0.04950336  0.00743731\n",
      "   -0.02902621]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  ...\n",
      "  [-0.03413375 -0.02158831  0.01005169 ... -0.0470572   0.02810354\n",
      "    0.00921623]\n",
      "  [-0.04178043  0.01801917  0.01572496 ... -0.03965739 -0.04862199\n",
      "    0.03428489]\n",
      "  [-0.00626981 -0.03842492  0.01870393 ...  0.02246121 -0.04567522\n",
      "    0.00639751]]]\n"
     ]
    }
   ],
   "source": [
    "train_embeddings_matrix = model.predict(train_tokens_matrix)\n",
    "test_embeddings_matrix = model.predict(test_tokens_matrix)\n",
    "print(train_embeddings_matrix.shape)\n",
    "print(test_embeddings_matrix.shape)\n",
    "print(train_embeddings_matrix)\n",
    "print(test_embeddings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step\n",
      "(2000, 737, 32)\n",
      "[[[ 0.03925676  0.03304542  0.04172217 ... -0.03614228 -0.04543976\n",
      "   -0.01497326]\n",
      "  [ 0.02836312 -0.04374274  0.02616371 ...  0.04891003 -0.02431585\n",
      "    0.04505942]\n",
      "  [-0.00052674  0.01896429  0.01779901 ...  0.02761943 -0.04287001\n",
      "   -0.0261164 ]\n",
      "  ...\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]]\n",
      "\n",
      " [[-0.04987419  0.03953192 -0.03945085 ... -0.04462079  0.0196293\n",
      "    0.04866723]\n",
      "  [-0.03372373  0.02600712  0.01134744 ...  0.00061792 -0.03395934\n",
      "   -0.03049546]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  ...\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]]\n",
      "\n",
      " [[-0.04763654  0.01742664 -0.02228661 ... -0.02611135  0.04441825\n",
      "    0.00218337]\n",
      "  [ 0.00125593  0.04882723 -0.04872293 ...  0.03247661  0.03251083\n",
      "   -0.02441573]\n",
      "  [ 0.03866008 -0.04943422  0.0226743  ... -0.00808561  0.02278126\n",
      "    0.04797177]\n",
      "  ...\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [ 0.03785595 -0.00170738 -0.04658076 ... -0.01559705  0.02645702\n",
      "   -0.01576991]\n",
      "  [ 0.00561095  0.03006662  0.00558661 ...  0.02182387 -0.03899449\n",
      "   -0.04203566]\n",
      "  ...\n",
      "  [ 0.00125593  0.04882723 -0.04872293 ...  0.03247661  0.03251083\n",
      "   -0.02441573]\n",
      "  [-0.04608832 -0.02723926 -0.03123413 ...  0.00839882  0.03151158\n",
      "   -0.0474172 ]\n",
      "  [-0.0280298   0.03197855  0.02746044 ...  0.03293723 -0.03853252\n",
      "    0.03860709]]\n",
      "\n",
      " [[-0.04278513  0.02390606  0.00973767 ... -0.02941272  0.00424205\n",
      "    0.01911007]\n",
      "  [ 0.04597196  0.02580262 -0.03122749 ... -0.02895995 -0.0229155\n",
      "    0.03037581]\n",
      "  [ 0.04909427  0.03035397 -0.0252364  ... -0.03577337  0.02589289\n",
      "   -0.00284795]\n",
      "  ...\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]]\n",
      "\n",
      " [[ 0.0074226  -0.02335132  0.03274801 ...  0.04950336  0.00743731\n",
      "   -0.02902621]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "   -0.0249073 ]\n",
      "  ...\n",
      "  [-0.03413375 -0.02158831  0.01005169 ... -0.0470572   0.02810354\n",
      "    0.00921623]\n",
      "  [-0.04178043  0.01801917  0.01572496 ... -0.03965739 -0.04862199\n",
      "    0.03428489]\n",
      "  [-0.00626981 -0.03842492  0.01870393 ...  0.02246121 -0.04567522\n",
      "    0.00639751]]]\n"
     ]
    }
   ],
   "source": [
    "embeddings_matrix = model.predict(tokens_matrix)\n",
    "print(embeddings_matrix.shape)\n",
    "print(embeddings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(737, 32)\n",
      "[[ 0.03925676  0.03304542  0.04172217 ... -0.03614228 -0.04543976\n",
      "  -0.01497326]\n",
      " [ 0.02836312 -0.04374274  0.02616371 ...  0.04891003 -0.02431585\n",
      "   0.04505942]\n",
      " [-0.00052674  0.01896429  0.01779901 ...  0.02761943 -0.04287001\n",
      "  -0.0261164 ]\n",
      " ...\n",
      " [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "  -0.0249073 ]\n",
      " [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "  -0.0249073 ]\n",
      " [-0.02765656 -0.02635467  0.04998653 ...  0.00771065  0.04405988\n",
      "  -0.0249073 ]]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_matrix[0].shape)\n",
    "print(embeddings_matrix[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 23584)\n",
      "[[ 0.03925676  0.03304542  0.04172217 ...  0.00771065  0.04405988\n",
      "  -0.0249073 ]\n",
      " [-0.04987419  0.03953192 -0.03945085 ...  0.00771065  0.04405988\n",
      "  -0.0249073 ]\n",
      " [-0.04763654  0.01742664 -0.02228661 ...  0.00771065  0.04405988\n",
      "  -0.0249073 ]\n",
      " ...\n",
      " [-0.02765656 -0.02635467  0.04998653 ...  0.03293723 -0.03853252\n",
      "   0.03860709]\n",
      " [-0.04278513  0.02390606  0.00973767 ...  0.00771065  0.04405988\n",
      "  -0.0249073 ]\n",
      " [ 0.0074226  -0.02335132  0.03274801 ...  0.02246121 -0.04567522\n",
      "   0.00639751]]\n"
     ]
    }
   ],
   "source": [
    "flattened_embeddings_matrix = embeddings_matrix.reshape(2000, 737 * 32)\n",
    "print(flattened_embeddings_matrix.shape)\n",
    "print(flattened_embeddings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23584,)\n",
      "[ 0.03925676  0.03304542  0.04172217 ...  0.00771065  0.04405988\n",
      " -0.0249073 ]\n"
     ]
    }
   ],
   "source": [
    "print(flattened_embeddings_matrix[0].shape)\n",
    "print(flattened_embeddings_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 23584)\n",
      "[[ 0.03925676  0.03304542  0.04172217 ...  0.00771065  0.04405988\n",
      "  -0.0249073 ]\n",
      " [-0.04987419  0.03953192 -0.03945085 ...  0.00771065  0.04405988\n",
      "  -0.0249073 ]\n",
      " [-0.04763654  0.01742664 -0.02228661 ...  0.00771065  0.04405988\n",
      "  -0.0249073 ]\n",
      " ...\n",
      " [-0.00263736  0.02807606 -0.04577314 ...  0.00771065  0.04405988\n",
      "  -0.0249073 ]\n",
      " [ 0.04790515 -0.00057345  0.01550138 ...  0.00771065  0.04405988\n",
      "  -0.0249073 ]\n",
      " [ 0.02195717  0.03610816 -0.00108435 ...  0.00771065  0.04405988\n",
      "  -0.0249073 ]]\n",
      "(600, 23584)\n",
      "[[-0.04987419  0.03953192 -0.03945085 ...  0.00771065  0.04405988\n",
      "  -0.0249073 ]\n",
      " [-0.04987419  0.03953192 -0.03945085 ...  0.00771065  0.04405988\n",
      "  -0.0249073 ]\n",
      " [-0.01734027 -0.00104775 -0.03079507 ...  0.00771065  0.04405988\n",
      "  -0.0249073 ]\n",
      " ...\n",
      " [-0.02765656 -0.02635467  0.04998653 ...  0.03293723 -0.03853252\n",
      "   0.03860709]\n",
      " [-0.04278513  0.02390606  0.00973767 ...  0.00771065  0.04405988\n",
      "  -0.0249073 ]\n",
      " [ 0.0074226  -0.02335132  0.03274801 ...  0.02246121 -0.04567522\n",
      "   0.00639751]]\n"
     ]
    }
   ],
   "source": [
    "flattened_train_embeddings_matrix = train_embeddings_matrix.reshape(1400, 737 * 32)\n",
    "flattened_test_embeddings_matrix = test_embeddings_matrix.reshape(600, 737 * 32)\n",
    "print(flattened_train_embeddings_matrix.shape)\n",
    "print(flattened_train_embeddings_matrix)\n",
    "print(flattened_test_embeddings_matrix.shape)\n",
    "print(flattened_test_embeddings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">737</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">160,000</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m737\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │       \u001b[38;5;34m160,000\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">160,000</span> (625.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m160,000\u001b[0m (625.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">160,000</span> (625.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m160,000\u001b[0m (625.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 737, 32) (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "labels = np.vstack(padded_sequences_df['Sentiment'].to_numpy())\n",
    "\n",
    "features = embeddings_matrix\n",
    "\n",
    "print(features.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp = Sequential()\n",
    "\n",
    "# mlp.add(Input(shape=(L * 32,)))\n",
    "# mlp.add(Embedding(input_dim=5000, output_dim=32, input_length=L))\n",
    "mlp.add(Dense(50, activation='relu'))\n",
    "mlp.add(Dropout(0.2))\n",
    "\n",
    "mlp.add(Dense(50, activation='relu'))\n",
    "mlp.add(Dropout(0.5))\n",
    "mlp.add(Dense(50, activation='relu'))\n",
    "mlp.add(Dropout(0.5))\n",
    "\n",
    "mlp.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "mlp.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1400, 23584)\n",
      "1400\n",
      "[-1 -1 -1 ...  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "print(type(flattened_train_embeddings_matrix))\n",
    "print(type(train_labels))\n",
    "print(flattened_train_embeddings_matrix.shape)\n",
    "print(len(train_labels))\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 23584)\n",
      "[[ 0.03925676  0.03304542  0.04172217 ...  0.00771065  0.04405988\n",
      "  -0.0249073 ]\n",
      " [-0.04987419  0.03953192 -0.03945085 ...  0.00771065  0.04405988\n",
      "  -0.0249073 ]\n",
      " [-0.04763654  0.01742664 -0.02228661 ...  0.00771065  0.04405988\n",
      "  -0.0249073 ]\n",
      " ...\n",
      " [-0.00263736  0.02807606 -0.04577314 ...  0.00771065  0.04405988\n",
      "  -0.0249073 ]\n",
      " [ 0.04790515 -0.00057345  0.01550138 ...  0.00771065  0.04405988\n",
      "  -0.0249073 ]\n",
      " [ 0.02195717  0.03610816 -0.00108435 ...  0.00771065  0.04405988\n",
      "  -0.0249073 ]]\n",
      "(600, 23584)\n",
      "[[-0.04987419  0.03953192 -0.03945085 ...  0.00771065  0.04405988\n",
      "  -0.0249073 ]\n",
      " [-0.04987419  0.03953192 -0.03945085 ...  0.00771065  0.04405988\n",
      "  -0.0249073 ]\n",
      " [-0.01734027 -0.00104775 -0.03079507 ...  0.00771065  0.04405988\n",
      "  -0.0249073 ]\n",
      " ...\n",
      " [-0.02765656 -0.02635467  0.04998653 ...  0.03293723 -0.03853252\n",
      "   0.03860709]\n",
      " [-0.04278513  0.02390606  0.00973767 ...  0.00771065  0.04405988\n",
      "  -0.0249073 ]\n",
      " [ 0.0074226  -0.02335132  0.03274801 ...  0.02246121 -0.04567522\n",
      "   0.00639751]]\n"
     ]
    }
   ],
   "source": [
    "tensor_flattened_train_embeddings_matrix = np.array([tf.convert_to_tensor(sub_arr) for sub_arr in flattened_train_embeddings_matrix])\n",
    "tensor_flattened_test_embeddings_matrix = np.array([tf.convert_to_tensor(sub_arr) for sub_arr in flattened_test_embeddings_matrix])\n",
    "train_labels[train_labels == -1] = 0\n",
    "test_labels[test_labels == -1] = 0\n",
    "tensor_train_labels = tf.convert_to_tensor(train_labels)\n",
    "tensor_test_labels = tf.convert_to_tensor(test_labels)\n",
    "print(tensor_flattened_train_embeddings_matrix.shape)\n",
    "print(tensor_flattened_train_embeddings_matrix)\n",
    "print(tensor_flattened_test_embeddings_matrix.shape)\n",
    "print(tensor_flattened_test_embeddings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 0 0 ... 1 1 1], shape=(1400,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1], shape=(600,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(tensor_train_labels)\n",
    "print(tensor_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 0 0 ... 1 1 1], shape=(1400,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1], shape=(600,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(tensor_train_labels)\n",
    "print(tensor_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5271 - loss: 0.7033\n",
      "Epoch 2/2\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5787 - loss: 0.6808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3089f0200>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(tensor_flattened_train_embeddings_matrix, tensor_train_labels, epochs=2, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2042 - loss: 0.7173    \n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.4259 - loss: 0.6884\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = mlp.evaluate(tensor_flattened_test_embeddings_matrix, tensor_test_labels)\n",
    "train_loss, train_accuracy = mlp.evaluate(tensor_flattened_train_embeddings_matrix, tensor_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.6449999809265137\n",
      "Train Loss: 0.656080424785614\n",
      "Test Accuracy: 0.5049999952316284\n",
      "Test Loss: 0.6914283037185669\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Loss: {train_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) One-Dimensional Convolutional Neural Network:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dsci552/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn = Sequential()\n",
    "cnn.add(Embedding(input_dim=top_words, output_dim=32, input_length=L))\n",
    "cnn.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(250, activation='relu'))\n",
    "cnn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1400, 737), (600, 737))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_token_features = np.concatenate((tokens_matrix[:700], tokens_matrix[1000:1700]))\n",
    "test_token_features = np.vstack((tokens_matrix[700:1000], tokens_matrix[1700:]))\n",
    "\n",
    "train_token_features.shape, test_token_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5232 - loss: 0.7334\n",
      "Epoch 2/2\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6346 - loss: 0.6413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x34cf973e0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(train_token_features, train_labels, epochs=2, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = cnn.evaluate(test_token_features, test_labels, verbose=0)\n",
    "train_loss, train_accuracy = cnn.evaluate(train_token_features, train_labels, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7478571534156799\n",
      "Train Loss: 0.43426474928855896\n",
      "Test Accuracy: 0.5916666388511658\n",
      "Test Loss: 0.7241743206977844\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Loss: {train_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) Long Short-Term Memory Recurrent Neural Network:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dsci552/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "lstm = Sequential([\n",
    "    LSTM(32, return_sequences=False, input_shape=(737, 32), dropout=0.2),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "lstm.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1400, 737, 32), (1400,))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embeddings_matrix.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - accuracy: 0.4738 - loss: 0.6937\n",
      "Epoch 2/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.5270 - loss: 0.6968\n",
      "Epoch 3/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.5571 - loss: 0.6858\n",
      "Epoch 4/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.5634 - loss: 0.6859\n",
      "Epoch 5/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.5230 - loss: 0.6949\n",
      "Epoch 6/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.5442 - loss: 0.6870\n",
      "Epoch 7/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.5559 - loss: 0.6861\n",
      "Epoch 8/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.5754 - loss: 0.6798\n",
      "Epoch 9/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.5530 - loss: 0.6858\n",
      "Epoch 10/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.5317 - loss: 0.6894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x35f5c61e0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.fit(train_embeddings_matrix, train_labels, epochs=10, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6673 - loss: 0.6766\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7039 - loss: 0.6716\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = lstm.evaluate(test_embeddings_matrix, test_labels)\n",
    "train_loss, train_accuracy = lstm.evaluate(train_embeddings_matrix, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.5557143092155457\n",
      "Train Loss: 0.685615599155426\n",
      "Test Accuracy: 0.5533333420753479\n",
      "Test Loss: 0.685391366481781\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Loss: {train_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Loss: {test_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsci552",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
